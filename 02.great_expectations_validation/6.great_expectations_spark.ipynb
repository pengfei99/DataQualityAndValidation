{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e09f8e-c623-4273-a718-2e8cf63dbbba",
   "metadata": {},
   "source": [
    "# Great Expectations on Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcc101-824b-48d4-8e9f-9aef3e1e9f22",
   "metadata": {},
   "source": [
    "Implementing unit tests on Pyspark DataFrames using Great Expections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1050cbce-99e2-48ae-a778-b91625680644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07301707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/12 09:45:54 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "23/01/12 09:45:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/12 09:45:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Great Expectations with Pandas DataFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801572a-7b3e-4f03-b6f9-035740e43bfa",
   "metadata": {},
   "source": [
    "## Load Raw DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad2811-d814-415c-afcd-4d5682bf4629",
   "metadata": {},
   "source": [
    "##### Load data from file and create a Pyspark Data Frame View named CAMPAIGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0be69a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "raw_df = spark.read.option(\"header\", True).option(\"inferSchema\",True).csv(\"../data/Kickstarter_projects_Feb19.csv\")\n",
    "raw_df.createOrReplaceTempView(\"CAMPAIGNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfd49ac-3e46-48fb-b0c3-2336e7def3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_df is a spark dataframe\n",
    "type(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1de4187f-4207-4bc7-bd1d-2899ca7859a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- sub_category: string (nullable = true)\n",
      " |-- launched_at: string (nullable = true)\n",
      " |-- deadline: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- goal_usd: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- blurb_length: string (nullable = true)\n",
      " |-- name_length: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- start_month: string (nullable = true)\n",
      " |-- end_month: string (nullable = true)\n",
      " |-- start_Q: string (nullable = true)\n",
      " |-- end_Q: string (nullable = true)\n",
      " |-- usd_pledged: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cd5303c-c94c-4bba-b7a2-c3d0d3d1d0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengfei/.cache/pypoetry/virtualenvs/dataqualityandvalidation-N5_6aXR_-py3.8/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# we can convert the spark dataframe to pandas dataframe\n",
    "raw_pdf=raw_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192548, 20)\n"
     ]
    }
   ],
   "source": [
    "print(raw_pdf.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "           id                                              name currency  \\\n0  1687733153             Socks of Speed and Socks of Elvenkind      USD   \n1   227936657  Power Punch Boot Camp: An All-Ages Graphic Novel      GBP   \n2   454186436    \"Live Printing with SX8: \"\"Squeegee Pulp Up\"\"\"      USD   \n3   629469071                 Lost Dog Street Band's Next Album      USD   \n4   183973060                             Qto-X, a Tiny Lantern      USD   \n\n  main_category    sub_category          launched_at             deadline  \\\n0         games  Tabletop Games  2018-10-30 20:00:02  2018-11-15 17:59:00   \n1        comics     Comic Books  2018-08-06 10:00:43  2018-09-05 10:00:43   \n2       fashion         Apparel  2017-06-09 15:41:03  2017-07-09 15:41:03   \n3         music  Country & Folk  2014-09-25 18:46:01  2014-11-10 06:00:00   \n4    technology         Gadgets  2016-11-28 16:35:11  2017-01-27 16:35:11   \n\n  duration    goal_usd        city    state country blurb_length name_length  \\\n0     16.0      2000.0     Menasha       WI      US           14           7   \n1     30.0  3870.99771  Shepperton  England      GB           24           8   \n2     30.0      1100.0   Manhattan       NY      US           21           7   \n3     45.0      3500.0   Nashville       TN      US           15           6   \n4     60.0     30000.0        Troy       MI      US           15           4   \n\n       status start_month end_month start_Q end_Q        usd_pledged  \n0  successful          10        11      Q4    Q4             6061.0  \n1  successful           8         9      Q3    Q3  3914.505120400001  \n2  successful           6         7      Q2    Q3             1110.0  \n3  successful           9        11      Q3    Q4             4807.0  \n4  successful          11         1      Q4    Q1            40368.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>currency</th>\n      <th>main_category</th>\n      <th>sub_category</th>\n      <th>launched_at</th>\n      <th>deadline</th>\n      <th>duration</th>\n      <th>goal_usd</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country</th>\n      <th>blurb_length</th>\n      <th>name_length</th>\n      <th>status</th>\n      <th>start_month</th>\n      <th>end_month</th>\n      <th>start_Q</th>\n      <th>end_Q</th>\n      <th>usd_pledged</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1687733153</td>\n      <td>Socks of Speed and Socks of Elvenkind</td>\n      <td>USD</td>\n      <td>games</td>\n      <td>Tabletop Games</td>\n      <td>2018-10-30 20:00:02</td>\n      <td>2018-11-15 17:59:00</td>\n      <td>16.0</td>\n      <td>2000.0</td>\n      <td>Menasha</td>\n      <td>WI</td>\n      <td>US</td>\n      <td>14</td>\n      <td>7</td>\n      <td>successful</td>\n      <td>10</td>\n      <td>11</td>\n      <td>Q4</td>\n      <td>Q4</td>\n      <td>6061.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>227936657</td>\n      <td>Power Punch Boot Camp: An All-Ages Graphic Novel</td>\n      <td>GBP</td>\n      <td>comics</td>\n      <td>Comic Books</td>\n      <td>2018-08-06 10:00:43</td>\n      <td>2018-09-05 10:00:43</td>\n      <td>30.0</td>\n      <td>3870.99771</td>\n      <td>Shepperton</td>\n      <td>England</td>\n      <td>GB</td>\n      <td>24</td>\n      <td>8</td>\n      <td>successful</td>\n      <td>8</td>\n      <td>9</td>\n      <td>Q3</td>\n      <td>Q3</td>\n      <td>3914.505120400001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>454186436</td>\n      <td>\"Live Printing with SX8: \"\"Squeegee Pulp Up\"\"\"</td>\n      <td>USD</td>\n      <td>fashion</td>\n      <td>Apparel</td>\n      <td>2017-06-09 15:41:03</td>\n      <td>2017-07-09 15:41:03</td>\n      <td>30.0</td>\n      <td>1100.0</td>\n      <td>Manhattan</td>\n      <td>NY</td>\n      <td>US</td>\n      <td>21</td>\n      <td>7</td>\n      <td>successful</td>\n      <td>6</td>\n      <td>7</td>\n      <td>Q2</td>\n      <td>Q3</td>\n      <td>1110.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>629469071</td>\n      <td>Lost Dog Street Band's Next Album</td>\n      <td>USD</td>\n      <td>music</td>\n      <td>Country &amp; Folk</td>\n      <td>2014-09-25 18:46:01</td>\n      <td>2014-11-10 06:00:00</td>\n      <td>45.0</td>\n      <td>3500.0</td>\n      <td>Nashville</td>\n      <td>TN</td>\n      <td>US</td>\n      <td>15</td>\n      <td>6</td>\n      <td>successful</td>\n      <td>9</td>\n      <td>11</td>\n      <td>Q3</td>\n      <td>Q4</td>\n      <td>4807.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>183973060</td>\n      <td>Qto-X, a Tiny Lantern</td>\n      <td>USD</td>\n      <td>technology</td>\n      <td>Gadgets</td>\n      <td>2016-11-28 16:35:11</td>\n      <td>2017-01-27 16:35:11</td>\n      <td>60.0</td>\n      <td>30000.0</td>\n      <td>Troy</td>\n      <td>MI</td>\n      <td>US</td>\n      <td>15</td>\n      <td>4</td>\n      <td>successful</td>\n      <td>11</td>\n      <td>1</td>\n      <td>Q4</td>\n      <td>Q1</td>\n      <td>40368.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pdf.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "c292e7c9-f672-433b-bd1c-8adcfed35be5",
   "metadata": {},
   "source": [
    "## Step1: Unit Tests on Raw Data\n",
    "\n",
    "To use GreatExpectation **expectations/validators** on dataframe, we need to first convert the `spark dataframe` to `ge SparkDFDataset`. You can find a full list of available `expectations` via this [page](https://greatexpectations.io/expectations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa4d98-1ec4-473b-b704-ad1ce6fc0766",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529d4bbd-d8f2-4c4f-90e4-2b8f9e0a3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.dataset import SparkDFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58dccdd1-faf2-475a-828d-369691c831b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before conversion <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "after conversion <class 'great_expectations.dataset.sparkdf_dataset.SparkDFDataset'>\n"
     ]
    }
   ],
   "source": [
    "# convert spark dataframe to ge sparkdf\n",
    "print(f\"before conversion {type(raw_df)}\")\n",
    "raw_test_df = SparkDFDataset(raw_df)\n",
    "print(f\"after conversion {type(raw_test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57e1dc-db7c-4698-ba3f-7c95e073a39d",
   "metadata": {},
   "source": [
    "### 1.1 Test 1: Check if mandatory columns exist\n",
    "\n",
    "Here we use a `expectation/validation` function called `expect_column_to_exist`. It takes a column name and returns a dictionary with various attributes. Below is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for : {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_to_exist\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"id\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {},\n",
      "  \"meta\": {},\n",
      "  \"success\": true,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test with a valid column name\n",
    "result=raw_test_df.expect_column_to_exist(\"id\")\n",
    "print(f\"result for : {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for : {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_to_exist\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"toto\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {},\n",
      "  \"meta\": {},\n",
      "  \"success\": false,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test with an invalid column name\n",
    "result=raw_test_df.expect_column_to_exist(\"toto\")\n",
    "print(f\"result for : {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can notice the first part of the dictionary describes the expectation (validation rule) and args. The second part is the result, in this example, there is nothing because this rule is very simple, no need to give extra information to understand the result. The most important attribute is **success** (bool), which tells us if the expectation is passed or not. In our example, it has value true when passes, otherwise it has value false. For more information, you can visit this [page](https://docs.greatexpectations.io/docs/terms/validation_result/)\n",
    "\n",
    "We can use this `expectation` to test if a dataframe contains a list of mandatory columns or not\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2f75de-701b-46ff-b93f-6487060285f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANDATORY_COLUMNS = [\n",
    "  \"id\",\n",
    "  \"currency\",\n",
    "  \"main_category\",\n",
    "  \"launched_at\",\n",
    "  \"deadline\",\n",
    "  \"country\",\n",
    "  \"status\",\n",
    "  \"usd_pledged\"  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffcc7029-53fc-44e3-b7a4-f3f64af48dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column id exists : PASSED\n",
      "Column currency exists : PASSED\n",
      "Column main_category exists : PASSED\n",
      "Column launched_at exists : PASSED\n",
      "Column deadline exists : PASSED\n",
      "Column country exists : PASSED\n",
      "Column status exists : PASSED\n",
      "Column usd_pledged exists : PASSED\n"
     ]
    }
   ],
   "source": [
    "for column in MANDATORY_COLUMNS:\n",
    "    try:\n",
    "        assert raw_test_df.expect_column_to_exist(column).success, f\"Uh oh! Mandatory column {column} does not exist: FAILED\"\n",
    "        print(f\"Column {column} exists : PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make a reusable, we can define a function\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def expect_df_to_contain_columns(df:SparkDFDataset,colList: List[str]):\n",
    "    badColList=[]\n",
    "    for column in colList:\n",
    "        if not df.expect_column_to_exist(column).success:\n",
    "            badColList.append(column)\n",
    "    if len(badColList)>0:\n",
    "        return False,badColList\n",
    "    else:\n",
    "        return True,badColList\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation status: True, output: []\n"
     ]
    }
   ],
   "source": [
    "status,output=expect_df_to_contain_columns(raw_test_df,\n",
    "                             MANDATORY_COLUMNS)\n",
    "\n",
    "print(f\"Expectation status: {status}, output: {output}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation status: False, output: ['toto', 'titi', 'tata']\n"
     ]
    }
   ],
   "source": [
    "status,output=expect_df_to_contain_columns(raw_test_df,[\"toto\",\"titi\",\"tata\"])\n",
    "\n",
    "print(f\"Expectation status: {status}, output: {output}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Test 2: Check if column value has specific type\n",
    "\n",
    "Here, we have two possible function which we can use:\n",
    "- expect_column_values_to_be_of_type(colName, type)\n",
    "- expect_column_values_to_be_in_type_list\n",
    "\n",
    "For more information, please visit this [page](https://greatexpectations.io/expectations/expect_column_values_to_be_of_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for : {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"id\",\n",
      "      \"type_\": \"IntegerType\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"observed_value\": \"IntegerType\"\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"success\": true,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "# test with a valid type\n",
    "result=raw_test_df.expect_column_values_to_be_of_type(\"id\",\"IntegerType\")\n",
    "print(f\"result content :\\n {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for : {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"id\",\n",
      "      \"type_\": \"StringType\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"observed_value\": \"IntegerType\"\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"success\": false,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test with an invalid type\n",
    "result=raw_test_df.expect_column_values_to_be_of_type(\"id\",\"StringType\")\n",
    "print(f\"result for : {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the above example, we can check if the column of the dataframe has certain type. Note if the data source is semi-structural, the column type is probably inferred by spark. So you may need to do give a schema when you create the data frame.\n",
    "\n",
    "And this time the result has an attribute called **observed_value**, this value is from the dataframe current schema."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "1cd0f66e-2b2e-4165-bff9-a4d97db0060f",
   "metadata": {},
   "source": [
    "### 1.3 Test 3: Check if mandatory columns contains null rows\n",
    "\n",
    "We can use **expect_column_values_to_not_be_null**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result content :\n",
      " {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"id\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"element_count\": 192548,\n",
      "    \"unexpected_count\": 0,\n",
      "    \"unexpected_percent\": 0.0,\n",
      "    \"unexpected_percent_total\": 0.0,\n",
      "    \"partial_unexpected_list\": []\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"success\": true,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test with column id\n",
    "result=raw_test_df.expect_column_values_to_not_be_null(\"id\")\n",
    "print(f\"result content :\\n {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result content :\n",
      " {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"main_category\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"element_count\": 192548,\n",
      "    \"unexpected_count\": 1,\n",
      "    \"unexpected_percent\": 0.0005193510189666992,\n",
      "    \"unexpected_percent_total\": 0.0005193510189666992,\n",
      "    \"partial_unexpected_list\": [\n",
      "      null\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"success\": false,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test with column main_category\n",
    "result=raw_test_df.expect_column_values_to_not_be_null(\"main_category\")\n",
    "print(f\"result content :\\n {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result contains much useful information:\n",
    "\n",
    "```text\n",
    "\"result\": {\n",
    "    \"element_count\": 192548, # total row\n",
    "    \"unexpected_count\": 1, # null row\n",
    "    \"unexpected_percent\": 0.0005193510189666992,\n",
    "    \"unexpected_percent_total\": 0.0005193510189666992,\n",
    "    \"partial_unexpected_list\": [\n",
    "      null\n",
    "    ]\n",
    "  }\n",
    "\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b845d31-9b6a-43e6-b3b1-962e0e825946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column id are not null: PASSED\n",
      "All items in column currency are not null: PASSED\n",
      "Uh oh! 1 of 192548 items in column main_category are null: FAILED\n",
      "Uh oh! 1 of 192548 items in column launched_at are null: FAILED\n",
      "Uh oh! 1 of 192548 items in column deadline are null: FAILED\n",
      "Uh oh! 1 of 192548 items in column country are null: FAILED\n",
      "Uh oh! 1 of 192548 items in column status are null: FAILED\n",
      "Uh oh! 1 of 192548 items in column usd_pledged are null: FAILED\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "for column in MANDATORY_COLUMNS:\n",
    "    try:\n",
    "        test_result = raw_test_df.expect_column_values_to_not_be_null(column)\n",
    "        assert test_result.success, \\\n",
    "            f\"Uh oh! {test_result.result['unexpected_count']} of {test_result.result['element_count']} items in column {column} are null: FAILED\"\n",
    "        print(f\"All items in column {column} are not null: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(e) \n",
    "    except AnalysisException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126629d-c209-4e09-9bc0-33abdca509e5",
   "metadata": {},
   "source": [
    "### 1.4 Test 4: Check if launched_at column is a valid datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result content :\n",
      " {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"launched_at\",\n",
      "      \"strftime_format\": \"%Y-%m-%d %H:%M:%S\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"element_count\": 192548,\n",
      "    \"missing_count\": 1,\n",
      "    \"missing_percent\": 0.0005193510189666992,\n",
      "    \"unexpected_count\": 562,\n",
      "    \"unexpected_percent\": 0.2918767885243603,\n",
      "    \"unexpected_percent_total\": 0.2918752726592849,\n",
      "    \"unexpected_percent_nonmissing\": 0.2918767885243603,\n",
      "    \"partial_unexpected_list\": [\n",
      "      \"Hip-Hop\",\n",
      "      \"Rock\",\n",
      "      \"Webseries\",\n",
      "      \"Musical\",\n",
      "      \"Kids\",\n",
      "      \"film & video\",\n",
      "      \"Painting\",\n",
      "      \"Webseries\",\n",
      "      \"Comedy\",\n",
      "      \"World Music\",\n",
      "      \"Children's Books\",\n",
      "      \"Indie Rock\",\n",
      "      \"Documentary\",\n",
      "      \"Cookbooks\",\n",
      "      \"Country & Folk\",\n",
      "      \"Hip-Hop\",\n",
      "      \"Jazz\",\n",
      "      \"Shorts\",\n",
      "      \"Classical Music\",\n",
      "      \"Art Books\"\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"success\": false,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# test with column id\n",
    "result=raw_test_df.expect_column_values_to_match_strftime_format('launched_at','%Y-%m-%d %H:%M:%S')\n",
    "print(f\"result content :\\n {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|        launched_at|count|\n",
      "+-------------------+-----+\n",
      "|2018-10-10 14:58:06|    3|\n",
      "|             People|    3|\n",
      "|2018-06-12 16:04:59|    3|\n",
      "|2017-11-15 23:29:31|    3|\n",
      "|               Kids|    3|\n",
      "|2018-11-26 17:30:30|    3|\n",
      "|2017-03-15 00:15:53|    3|\n",
      "|        Young Adult|    3|\n",
      "|2018-01-31 18:00:33|    3|\n",
      "|              Music|    3|\n",
      "|           Textiles|    3|\n",
      "|2014-11-21 18:01:56|    3|\n",
      "|              games|    3|\n",
      "|2018-10-02 11:05:11|    3|\n",
      "|2016-09-06 19:49:38|    3|\n",
      "|2018-03-27 15:01:06|    3|\n",
      "|2018-02-01 22:34:51|    3|\n",
      "|               food|    3|\n",
      "|2017-07-01 20:27:21|    3|\n",
      "|           Academic|    3|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "raw_df.groupby(col(\"launched_at\")).count().orderBy(col(\"count\")).filter(col(\"count\")>2).show(20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With above example, we are sure someone messed with the column, the result section are very useful\n",
    "\n",
    "```text\n",
    "\"result\": {\n",
    "    \"element_count\": 192548, # all rows\n",
    "    \"missing_count\": 1,  # null rows\n",
    "    \"missing_percent\": 0.0005193510189666992,\n",
    "    \"unexpected_count\": 562, # row that does not match the format\n",
    "    \"unexpected_percent\": 0.2918767885243603,\n",
    "    \"unexpected_percent_total\": 0.2918752726592849,\n",
    "    \"unexpected_percent_nonmissing\": 0.2918767885243603,\n",
    "    \"partial_unexpected_list\": [  # row values that does not match\n",
    "      \"Hip-Hop\",\n",
    "      \"Rock\",\n",
    "      \"Webseries\",\n",
    "      \"Musical\",\n",
    "      \"Kids\",\n",
    "      \"film & video\",\n",
    "      ...]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a4ac1bf-ae26-45fd-a96e-e2cb654602a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "'0.29% is not a valid date time format'"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result =  raw_test_df.expect_column_values_to_match_strftime_format('launched_at','%Y-%m-%d %H:%M:%S')\n",
    "f\"\"\"{round(test_result.result['unexpected_percent'], 2)}% is not a valid date time format\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12065115-26cc-4e9f-b2bb-61a37d7c5a24",
   "metadata": {},
   "source": [
    "### 1.5 Test 5: Check if deadline is a valid datetime format\n",
    "\n",
    "Same for dealine column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fdfc143-4453-4492-8fd8-7551b213e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "'0.04% is not a valid date time format'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result =  raw_test_df.expect_column_values_to_match_strftime_format('deadline','%Y-%m-%d %H:%M:%S')\n",
    "f\"\"\"{round(test_result.result['unexpected_percent'], 2)}% is not a valid date time format\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c10ed6-2ecd-4e31-8cc9-f044a747569e",
   "metadata": {},
   "source": [
    "### 1.6 Test 6: Check if id is unique\n",
    "\n",
    "Some column values must be unique. We can use the function **expect_column_values_to_be_unique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result content :\n",
      " {\n",
      "  \"expectation_config\": {\n",
      "    \"meta\": {},\n",
      "    \"expectation_type\": \"expect_column_values_to_be_unique\",\n",
      "    \"kwargs\": {\n",
      "      \"column\": \"id\",\n",
      "      \"result_format\": \"BASIC\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"element_count\": 192548,\n",
      "    \"missing_count\": 0,\n",
      "    \"missing_percent\": 0.0,\n",
      "    \"unexpected_count\": 48162,\n",
      "    \"unexpected_percent\": 25.01298377547417,\n",
      "    \"unexpected_percent_total\": 25.01298377547417,\n",
      "    \"unexpected_percent_nonmissing\": 25.01298377547417,\n",
      "    \"partial_unexpected_list\": [\n",
      "      39036,\n",
      "      39036,\n",
      "      39235,\n",
      "      39235,\n",
      "      50419,\n",
      "      50419,\n",
      "      188790,\n",
      "      188790,\n",
      "      342881,\n",
      "      342881,\n",
      "      358771,\n",
      "      358771,\n",
      "      377517,\n",
      "      377517,\n",
      "      390870,\n",
      "      390870,\n",
      "      442565,\n",
      "      442565,\n",
      "      538372,\n",
      "      538372\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"success\": false,\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test with column id\n",
    "result=raw_test_df.expect_column_values_to_be_unique('id')\n",
    "print(f\"result content :\\n {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the above example, we can have the following output, we can detect all duplicated row values in column id\n",
    "\n",
    "```text\n",
    "'element_count': 192548,\n",
    "'missing_count': 0,\n",
    "'missing_percent': 0.0,\n",
    "'unexpected_count': 48162,\n",
    "'unexpected_percent': 25.01298377547417,\n",
    "'unexpected_percent_total': 25.01298377547417,\n",
    "'unexpected_percent_nonmissing': 25.01298377547417,\n",
    "'partial_unexpected_list': [39036, 39036, 39235, 39235, 50419, 50419, 188790, 188790, 342881, 342881, 358771, 358771, 377517, 377517, 390870, 390870, 442565, 442565, 538372, 538372]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'element_count': 192548, 'missing_count': 0, 'missing_percent': 0.0, 'unexpected_count': 48162, 'unexpected_percent': 25.01298377547417, 'unexpected_percent_total': 25.01298377547417, 'unexpected_percent_nonmissing': 25.01298377547417, 'partial_unexpected_list': [39036, 39036, 39235, 39235, 50419, 50419, 188790, 188790, 342881, 342881, 358771, 358771, 377517, 377517, 390870, 390870, 442565, 442565, 538372, 538372]}\n"
     ]
    }
   ],
   "source": [
    "print(result.result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd9127e-df76-46e3-a99c-681e6112f297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uh oh! 48162 of 192548 items or 25.01% are not unique: FAILED\n"
     ]
    }
   ],
   "source": [
    "test_result = raw_test_df.expect_column_values_to_be_unique(\"id\")\n",
    "failed_msg = \" \".join([f\"\"\"Uh oh!\"\"\",\n",
    "              f\"\"\"{test_result.result['unexpected_count']} of {test_result.result['element_count']} items\"\"\",\n",
    "              f\"\"\"or {round(test_result.result['unexpected_percent'],2)}% are not unique: FAILED\"\"\"])\n",
    "print(f\"\"\"{'Column id is unique: PASSED' if test_result.success else failed_msg}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc94c0-ea6e-4ced-9ac2-2fb4c5898aa1",
   "metadata": {},
   "source": [
    "## 2 Step2 : Filter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09287e6",
   "metadata": {},
   "source": [
    "### Business Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b91568",
   "metadata": {},
   "source": [
    "1. Should filter campaigns in country \"US\" only\n",
    "2. Should filter campaigns that were active in 2017 and 2018 only based on \"launch_at\" and \"deadline\".\n",
    "3. Include only the below categories: \n",
    "    - art\n",
    "    - publishing\n",
    "    - film & video\n",
    "    - technology\n",
    "    - journalism\n",
    "    - food\n",
    "    - dance\n",
    "    - photography\n",
    "    - games\n",
    "    - crafts\n",
    "    - music\n",
    "    - comics\n",
    "    - theater\n",
    "    - design\n",
    "4. Should include successful campaigns only\n",
    "5. Should include USD currency only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797475bd-9840-4167-893f-748a66320666",
   "metadata": {},
   "source": [
    "### Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2e361-7ee2-4612-bdaa-e728936c3b96",
   "metadata": {},
   "source": [
    "##### Filter Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d6a240-a26d-4bae-b17f-dde9c0208386",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_CATEGORIES = [\n",
    "    'art',\n",
    "    'publishing',\n",
    "    'film & video',\n",
    "    'technology',\n",
    "    'journalism',\n",
    "    'food',\n",
    "    'dance',\n",
    "    'photography',\n",
    "    'games',\n",
    "    'crafts',\n",
    "    'music',\n",
    "    'comics',\n",
    "    'theater',\n",
    "    'design'    \n",
    "]\n",
    "ASSESSMENT_YEAR = ['2017','2018']\n",
    "COUNTRY = 'US'\n",
    "CURRENCY = 'USD'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627614a-ec08-4c5a-a378-f4226baa0faf",
   "metadata": {},
   "source": [
    "##### Generate a Reference Data for Assessment Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4723e558-1a00-49f2-8d3d-8e74baee4303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  assessment_year period_start_dt period_end_dt\n0            2017      2016-07-01    2017-06-30\n1            2018      2017-07-01    2018-06-30",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>assessment_year</th>\n      <th>period_start_dt</th>\n      <th>period_end_dt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017</td>\n      <td>2016-07-01</td>\n      <td>2017-06-30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018</td>\n      <td>2017-07-01</td>\n      <td>2018-06-30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessment_year_reference = {\n",
    "    'assessment_year': ['2017', '2018'], \n",
    "    'period_start_dt': ['2016-07-01', '2017-07-01'],\n",
    "    'period_end_dt': ['2017-06-30', '2018-06-30'],\n",
    "}\n",
    "ay_df = pd.DataFrame(data=assessment_year_reference)\n",
    "ay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7bdcd-702e-4d07-99bc-c37794b42244",
   "metadata": {},
   "source": [
    "##### Convert to a Pyspark DataFrame to be able to join to CAMPAIGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6052cf17-19b2-49db-a2df-2b9a4a6acfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_ay_df = spark.createDataFrame(ay_df) \n",
    "spark_ay_df.createOrReplaceTempView(\"assessment_year_ref\")\n",
    "type(spark_ay_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b742b5-e495-4b1e-ba33-2377ffc50dfa",
   "metadata": {},
   "source": [
    "##### Apply Transformation and create a view named FILTERED_CAMPAIGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0d7691c-1fae-4c04-b169-f853d92357c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = spark.sql(f\"\"\"\n",
    "    SELECT id,\n",
    "           name,\n",
    "           currency,\n",
    "           main_category,\n",
    "           launched_at,\n",
    "           deadline,\n",
    "           goal_usd,\n",
    "           country,\n",
    "           usd_pledged,\n",
    "           status,\n",
    "           assessment_year\n",
    "    FROM (SELECT t.*,\n",
    "               ay.assessment_year,\n",
    "               row_number() OVER (\n",
    "                   PARTITION BY t.id\n",
    "                   ORDER BY t.launched_at, \n",
    "                            ay.assessment_year DESC) row_no\n",
    "          FROM CAMPAIGNS t\n",
    "          INNER JOIN assessment_year_ref ay\n",
    "              ON TO_DATE(t.launched_at) <= ay.period_end_dt \n",
    "              AND t.deadline > ay.period_start_dt\n",
    "          WHERE country = '{COUNTRY}'\n",
    "          AND status = 'successful'\n",
    "          AND main_category IN ('{\"','\".join(MAIN_CATEGORIES)}')\n",
    "          AND ay.assessment_year IN ('{\"','\".join(ASSESSMENT_YEAR)}')\n",
    "          AND currency = '{CURRENCY}'\n",
    "   ) WHERE row_no = 1 \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c38957-8867-4d44-a849-af0113e3ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.createOrReplaceTempView(\"FILTERED_CAMPAIGNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3545ad-970d-4923-a390-974fa4dcd56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "               id                                       name currency  \\\n0      1000154193                                  Euphorium      USD   \n1      1001228129                   Adult Colour Debut Album      USD   \n2      1001347176                        The Book of Maxwell      USD   \n3      1001543887                  Peak View Brewing Company      USD   \n4      1001785505   Fidget Hoop: IT'S NOT WHAT IT LOOKS LIKE      USD   \n...           ...                                        ...      ...   \n17851   999182097   \"Make 100 / \"\"Do Something\"\" Art Prints\"      USD   \n17852   999205973     dÃÂz nÃÂ¼ts: Small Sack. Big Heart.      USD   \n17853    99924900  The Space Hobo Bottlecap Divination Board      USD   \n17854   999341311          Vann the Artist Paints A Necklace      USD   \n17855   999587299                Arcane Sally & Mr. Steam #2      USD   \n\n      main_category          launched_at             deadline goal_usd  \\\n0      film & video  2018-03-16 21:07:47  2018-04-10 21:07:47   1500.0   \n1             music  2017-05-25 20:27:33  2017-06-24 20:27:33   2200.0   \n2        journalism  2017-07-12 21:47:37  2017-08-07 02:59:00   1500.0   \n3              food  2016-09-10 12:25:04  2016-10-10 12:25:04  15000.0   \n4             games  2018-03-07 14:33:20  2018-04-21 13:33:20    900.0   \n...             ...                  ...                  ...      ...   \n17851           art  2017-01-30 21:24:49  2017-02-14 21:24:49   1600.0   \n17852          food  2016-07-22 05:09:14  2016-08-22 05:09:14   1000.0   \n17853           art  2017-01-01 18:50:39  2017-01-16 20:00:00   2500.0   \n17854    publishing  2017-07-28 22:52:48  2017-09-01 04:59:00   4750.0   \n17855        comics  2016-08-25 23:09:58  2016-09-19 06:59:00   1500.0   \n\n      country usd_pledged      status assessment_year  \n0          US      1500.0  successful            2018  \n1          US      2415.0  successful            2017  \n2          US      1804.0  successful            2018  \n3          US     15018.0  successful            2017  \n4          US      1051.0  successful            2018  \n...       ...         ...         ...             ...  \n17851      US      4906.0  successful            2017  \n17852      US      3622.0  successful            2017  \n17853      US      6636.0  successful            2017  \n17854      US      5058.0  successful            2018  \n17855      US      6771.0  successful            2017  \n\n[17856 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>currency</th>\n      <th>main_category</th>\n      <th>launched_at</th>\n      <th>deadline</th>\n      <th>goal_usd</th>\n      <th>country</th>\n      <th>usd_pledged</th>\n      <th>status</th>\n      <th>assessment_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000154193</td>\n      <td>Euphorium</td>\n      <td>USD</td>\n      <td>film &amp; video</td>\n      <td>2018-03-16 21:07:47</td>\n      <td>2018-04-10 21:07:47</td>\n      <td>1500.0</td>\n      <td>US</td>\n      <td>1500.0</td>\n      <td>successful</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001228129</td>\n      <td>Adult Colour Debut Album</td>\n      <td>USD</td>\n      <td>music</td>\n      <td>2017-05-25 20:27:33</td>\n      <td>2017-06-24 20:27:33</td>\n      <td>2200.0</td>\n      <td>US</td>\n      <td>2415.0</td>\n      <td>successful</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001347176</td>\n      <td>The Book of Maxwell</td>\n      <td>USD</td>\n      <td>journalism</td>\n      <td>2017-07-12 21:47:37</td>\n      <td>2017-08-07 02:59:00</td>\n      <td>1500.0</td>\n      <td>US</td>\n      <td>1804.0</td>\n      <td>successful</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1001543887</td>\n      <td>Peak View Brewing Company</td>\n      <td>USD</td>\n      <td>food</td>\n      <td>2016-09-10 12:25:04</td>\n      <td>2016-10-10 12:25:04</td>\n      <td>15000.0</td>\n      <td>US</td>\n      <td>15018.0</td>\n      <td>successful</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1001785505</td>\n      <td>Fidget Hoop: IT'S NOT WHAT IT LOOKS LIKE</td>\n      <td>USD</td>\n      <td>games</td>\n      <td>2018-03-07 14:33:20</td>\n      <td>2018-04-21 13:33:20</td>\n      <td>900.0</td>\n      <td>US</td>\n      <td>1051.0</td>\n      <td>successful</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17851</th>\n      <td>999182097</td>\n      <td>\"Make 100 / \"\"Do Something\"\" Art Prints\"</td>\n      <td>USD</td>\n      <td>art</td>\n      <td>2017-01-30 21:24:49</td>\n      <td>2017-02-14 21:24:49</td>\n      <td>1600.0</td>\n      <td>US</td>\n      <td>4906.0</td>\n      <td>successful</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>17852</th>\n      <td>999205973</td>\n      <td>dÃÂz nÃÂ¼ts: Small Sack. Big Heart.</td>\n      <td>USD</td>\n      <td>food</td>\n      <td>2016-07-22 05:09:14</td>\n      <td>2016-08-22 05:09:14</td>\n      <td>1000.0</td>\n      <td>US</td>\n      <td>3622.0</td>\n      <td>successful</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>17853</th>\n      <td>99924900</td>\n      <td>The Space Hobo Bottlecap Divination Board</td>\n      <td>USD</td>\n      <td>art</td>\n      <td>2017-01-01 18:50:39</td>\n      <td>2017-01-16 20:00:00</td>\n      <td>2500.0</td>\n      <td>US</td>\n      <td>6636.0</td>\n      <td>successful</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>17854</th>\n      <td>999341311</td>\n      <td>Vann the Artist Paints A Necklace</td>\n      <td>USD</td>\n      <td>publishing</td>\n      <td>2017-07-28 22:52:48</td>\n      <td>2017-09-01 04:59:00</td>\n      <td>4750.0</td>\n      <td>US</td>\n      <td>5058.0</td>\n      <td>successful</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>17855</th>\n      <td>999587299</td>\n      <td>Arcane Sally &amp; Mr. Steam #2</td>\n      <td>USD</td>\n      <td>comics</td>\n      <td>2016-08-25 23:09:58</td>\n      <td>2016-09-19 06:59:00</td>\n      <td>1500.0</td>\n      <td>US</td>\n      <td>6771.0</td>\n      <td>successful</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>17856 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc82351-dcb4-45cd-b59f-ba5d012a6207",
   "metadata": {},
   "source": [
    "## Unit Tests on Filtered Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e21e0-0f30-4f1c-8d6d-96fa3ef2ee82",
   "metadata": {},
   "source": [
    "##### Create a SparkDFDataset instance of filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3d7f3ce-2c05-4914-aad9-c0b1e0fff86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_df = SparkDFDataset(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b561fa-a10a-4b44-8f45-37ef77bc2523",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 1: Check if main_category within scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d54aabb-ce9d-4ad0-b7cf-3c398460a40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories are within scope: PASSED\n"
     ]
    }
   ],
   "source": [
    "test_result = filtered_test_df.expect_column_values_to_be_in_set(\"main_category\", MAIN_CATEGORIES)\n",
    "print(f\"\"\"Categories are within scope: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d1ae9-7b21-4a39-8f7c-f2aaa8470afa",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 2: Check if country is equal to \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f033b595-ae76-40be-b702-4f0837f514fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:============================================>         (165 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All campaigns are done in the country of USA: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_result = filtered_test_df.expect_column_values_to_be_in_set(\"country\", [\"US\"])\n",
    "print(f\"\"\"All campaigns are done in the country of USA: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861de98-649f-4fae-8dac-13e8fef977f7",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 3: Check if status = 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76329016-951d-4637-992c-f6ad03b7e828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All campaigns are successful: PASSED\n"
     ]
    }
   ],
   "source": [
    "test_result = filtered_test_df.expect_column_values_to_be_in_set(\"status\", [\"successful\"])\n",
    "print(f\"\"\"All campaigns are successful: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f806c-d6d5-4c4b-94bc-f5f85cde0b5e",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 4: Check if currency = 'USD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e186b06b-173a-4527-b39e-62b9707fbe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:====================================================>(198 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All campaigns are successful: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_result = filtered_test_df.expect_column_values_to_be_in_set(\"currency\", [\"USD\"])\n",
    "print(f\"\"\"All campaigns are successful: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7ca3e-5601-4686-a78c-e8482c0c9b07",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 5: Check if mandatory columns are not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3df4abfa-ef33-4e10-b7d1-2e4d726220cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column id are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column currency are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column main_category are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column launched_at are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column deadline are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column country are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column status are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 151:===================================================> (195 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in column usd_pledged are not null: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for column in MANDATORY_COLUMNS:\n",
    "    try:\n",
    "        test_result = filtered_test_df.expect_column_values_to_not_be_null(column)\n",
    "        assert test_result.success, f\"Uh oh! {test_result.result['unexpected_count']} of {test_result.result['element_count']} items in column {column} are null: FAILED\"\n",
    "        print(f\"All items in column {column} are not null: PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2c348-5774-4cf5-8549-261ecfb4ab27",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 6: Check if id is unique in each assessment year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba39e78b-3731-4c9f-81b2-343b1dbb682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:====================================================>(197 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id column is unique for each assessment year: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_result = filtered_test_df.expect_compound_columns_to_be_unique([\"id\", \"assessment_year\"])\n",
    "print(f\"\"\"id column is unique for each assessment year: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0a1dd-1e84-4afa-828f-4077ddf2200a",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 7: Check if launched_at is a valid datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41dcb343-2848-40a7-9df5-f81afbe89733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "'launched_at column values are compliant to datetime format: PASSED'"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result =  filtered_test_df.expect_column_values_to_match_strftime_format('launched_at','%Y-%m-%d %H:%M:%S')\n",
    "f\"\"\"launched_at column values are compliant to datetime format: {'PASSED' if test_result.success else 'FAILED'}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b87b8d-131d-4611-96a9-d7d8651ed22a",
   "metadata": {},
   "source": [
    "#### Filtered DF Test 8: Check if deadline is a valid datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66f23789-5e71-4330-b22c-85361243cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "'deadline column values are compliant to datetime format: PASSED'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result =  filtered_test_df.expect_column_values_to_match_strftime_format('deadline','%Y-%m-%d %H:%M:%S')\n",
    "f\"\"\"deadline column values are compliant to datetime format: {'PASSED' if test_result.success else 'FAILED'}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d71ab-0fa9-433a-8893-59bb9513c53c",
   "metadata": {},
   "source": [
    "## Standardise Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169be2eb-cbef-4b99-979a-258d375986f1",
   "metadata": {},
   "source": [
    "### Business Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ec98a-4966-410f-90a1-3eb2883ac2a8",
   "metadata": {},
   "source": [
    "##### Standardise categories - Reduce to 6 final metric categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c199a42d-43de-406a-9803-46ff9272d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_CATEGORIES = [\n",
    "    'art, crafts, photography & design',\n",
    "    'dance & theater',\n",
    "    'music, film & video',\n",
    "    'comics, publishing & journalism',\n",
    "    'games & technology',\n",
    "    'food'  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803a791-1a7b-4a55-8b43-f4a7e28cf3f0",
   "metadata": {},
   "source": [
    "##### Categorise based on Total Pledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d8e0b29-31aa-4593-adce-17b25ae62a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLEDGE_CATEGORIES = [\n",
    "    '100 Thousand and under',\n",
    "    'Between 100 Thousand and 500 Thousand',\n",
    "    'Between 500 Thousand and 1 Million',\n",
    "    'Between 1 Million and 5 Million',\n",
    "    '5 Million and over'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f96056-977b-4748-982d-ddff310a3c29",
   "metadata": {},
   "source": [
    "### Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13f4c1-d6c9-4242-8628-5045adba8e0c",
   "metadata": {},
   "source": [
    "##### Apply Transformation and create a view named STANDARDISED_CAMPAIGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e014bda2-dbd2-4e0d-ab57-d3a533cce6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardised_df = spark.sql(f\"\"\"\n",
    "    SELECT t.*,\n",
    "         CASE \n",
    "             WHEN main_category IN ('art','crafts','photography','design') THEN 'art, crafts, photography & design'\n",
    "              WHEN main_category IN ('dance','theater') THEN 'dance & theater'\n",
    "              WHEN main_category IN ('music','film & video') THEN 'music, film & video'\n",
    "              WHEN main_category IN ('comics','publishing','journalism') THEN 'comics, publishing & journalism'\n",
    "              WHEN main_category IN ('games', 'technology') THEN 'games & technology'\n",
    "              WHEN main_category IN ('food') THEN 'food'                  \n",
    "             END metric_category,\n",
    "         CASE WHEN usd_pledged <= 100000 THEN '100 Thousand and under'\n",
    "              WHEN usd_pledged > 100000 AND usd_pledged < 500000 THEN 'Between 100 Thousand and 500 Thousand'\n",
    "              WHEN usd_pledged > 500000 AND usd_pledged < 1000000 THEN 'Between 500 Thousand and 1 Million'\n",
    "              WHEN usd_pledged > 1000000 AND usd_pledged < 5000000 THEN 'Between 1 Million and 5 Million'\n",
    "           ELSE '5 Million and over'\n",
    "           END pledge_category    \n",
    "    FROM FILTERED_CAMPAIGNS t       \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce783c3c-debd-4072-8a54-89bef088118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardised_df.createOrReplaceTempView(\"STANDARDISED_CAMPAIGNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d93a02b-f847-4566-a99e-ed86eb833169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "               id                                               name currency  \\\n0        10064783                      WarmUp: A High-Protein Coffee      USD   \n1      1010419089                      Silver Linings by J.R. Mounts      USD   \n2      1017132344    Princes of the Universe: a Nino Malong Art Book      USD   \n3      1029958445  Art of Cardistry - Geometry Playing Cards Vers...      USD   \n4      1036177598  Dead Duck & Zombie Chick Radio Show (vinyl pre...      USD   \n...           ...                                                ...      ...   \n17851   980019524  Hushme - The World's First Voice Mask For Smar...      USD   \n17852   981977447  Get Purer Hot Water with World's Most Advanced...      USD   \n17853   982043894  Through the Window - A photographic tale of ca...      USD   \n17854   993614901  Send me on The Arctic Circle 2018 Arts & Scien...      USD   \n17855    99924900          The Space Hobo Bottlecap Divination Board      USD   \n\n      main_category          launched_at             deadline  goal_usd  \\\n0              food  2016-11-14 17:55:34  2016-12-14 17:55:34    8000.0   \n1            comics  2018-01-10 02:10:01  2018-02-16 05:00:00     500.0   \n2        publishing  2016-07-31 19:03:04  2016-09-05 01:00:00    1200.0   \n3             games  2018-03-03 01:54:57  2018-03-13 00:54:57    1000.0   \n4            comics  2018-03-27 11:53:02  2018-04-26 11:53:02    7000.0   \n...             ...                  ...                  ...       ...   \n17851    technology  2017-05-10 12:55:45  2017-06-09 12:55:45   70000.0   \n17852    technology  2017-05-01 15:33:19  2017-06-15 04:00:00  125000.0   \n17853   photography  2017-09-03 22:42:47  2017-10-03 22:42:47    7500.0   \n17854           art  2018-01-29 16:58:19  2018-02-28 16:58:19   13500.0   \n17855           art  2017-01-01 18:50:39  2017-01-16 20:00:00    2500.0   \n\n      country usd_pledged      status assessment_year  \\\n0          US      8599.0  successful            2017   \n1          US      2914.5  successful            2018   \n2          US      1670.0  successful            2017   \n3          US      1630.0  successful            2018   \n4          US      7656.0  successful            2018   \n...       ...         ...         ...             ...   \n17851      US     71880.0  successful            2017   \n17852      US    164866.0  successful            2017   \n17853      US     11341.0  successful            2018   \n17854      US     14639.0  successful            2018   \n17855      US      6636.0  successful            2017   \n\n                         metric_category  \\\n0                                   food   \n1        comics, publishing & journalism   \n2        comics, publishing & journalism   \n3                     games & technology   \n4        comics, publishing & journalism   \n...                                  ...   \n17851                 games & technology   \n17852                 games & technology   \n17853  art, crafts, photography & design   \n17854  art, crafts, photography & design   \n17855  art, crafts, photography & design   \n\n                             pledge_category  \n0                     100 Thousand and under  \n1                     100 Thousand and under  \n2                     100 Thousand and under  \n3                     100 Thousand and under  \n4                     100 Thousand and under  \n...                                      ...  \n17851                 100 Thousand and under  \n17852  Between 100 Thousand and 500 Thousand  \n17853                 100 Thousand and under  \n17854                 100 Thousand and under  \n17855                 100 Thousand and under  \n\n[17856 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>currency</th>\n      <th>main_category</th>\n      <th>launched_at</th>\n      <th>deadline</th>\n      <th>goal_usd</th>\n      <th>country</th>\n      <th>usd_pledged</th>\n      <th>status</th>\n      <th>assessment_year</th>\n      <th>metric_category</th>\n      <th>pledge_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10064783</td>\n      <td>WarmUp: A High-Protein Coffee</td>\n      <td>USD</td>\n      <td>food</td>\n      <td>2016-11-14 17:55:34</td>\n      <td>2016-12-14 17:55:34</td>\n      <td>8000.0</td>\n      <td>US</td>\n      <td>8599.0</td>\n      <td>successful</td>\n      <td>2017</td>\n      <td>food</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1010419089</td>\n      <td>Silver Linings by J.R. Mounts</td>\n      <td>USD</td>\n      <td>comics</td>\n      <td>2018-01-10 02:10:01</td>\n      <td>2018-02-16 05:00:00</td>\n      <td>500.0</td>\n      <td>US</td>\n      <td>2914.5</td>\n      <td>successful</td>\n      <td>2018</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1017132344</td>\n      <td>Princes of the Universe: a Nino Malong Art Book</td>\n      <td>USD</td>\n      <td>publishing</td>\n      <td>2016-07-31 19:03:04</td>\n      <td>2016-09-05 01:00:00</td>\n      <td>1200.0</td>\n      <td>US</td>\n      <td>1670.0</td>\n      <td>successful</td>\n      <td>2017</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1029958445</td>\n      <td>Art of Cardistry - Geometry Playing Cards Vers...</td>\n      <td>USD</td>\n      <td>games</td>\n      <td>2018-03-03 01:54:57</td>\n      <td>2018-03-13 00:54:57</td>\n      <td>1000.0</td>\n      <td>US</td>\n      <td>1630.0</td>\n      <td>successful</td>\n      <td>2018</td>\n      <td>games &amp; technology</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1036177598</td>\n      <td>Dead Duck &amp; Zombie Chick Radio Show (vinyl pre...</td>\n      <td>USD</td>\n      <td>comics</td>\n      <td>2018-03-27 11:53:02</td>\n      <td>2018-04-26 11:53:02</td>\n      <td>7000.0</td>\n      <td>US</td>\n      <td>7656.0</td>\n      <td>successful</td>\n      <td>2018</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17851</th>\n      <td>980019524</td>\n      <td>Hushme - The World's First Voice Mask For Smar...</td>\n      <td>USD</td>\n      <td>technology</td>\n      <td>2017-05-10 12:55:45</td>\n      <td>2017-06-09 12:55:45</td>\n      <td>70000.0</td>\n      <td>US</td>\n      <td>71880.0</td>\n      <td>successful</td>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>17852</th>\n      <td>981977447</td>\n      <td>Get Purer Hot Water with World's Most Advanced...</td>\n      <td>USD</td>\n      <td>technology</td>\n      <td>2017-05-01 15:33:19</td>\n      <td>2017-06-15 04:00:00</td>\n      <td>125000.0</td>\n      <td>US</td>\n      <td>164866.0</td>\n      <td>successful</td>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n    </tr>\n    <tr>\n      <th>17853</th>\n      <td>982043894</td>\n      <td>Through the Window - A photographic tale of ca...</td>\n      <td>USD</td>\n      <td>photography</td>\n      <td>2017-09-03 22:42:47</td>\n      <td>2017-10-03 22:42:47</td>\n      <td>7500.0</td>\n      <td>US</td>\n      <td>11341.0</td>\n      <td>successful</td>\n      <td>2018</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>17854</th>\n      <td>993614901</td>\n      <td>Send me on The Arctic Circle 2018 Arts &amp; Scien...</td>\n      <td>USD</td>\n      <td>art</td>\n      <td>2018-01-29 16:58:19</td>\n      <td>2018-02-28 16:58:19</td>\n      <td>13500.0</td>\n      <td>US</td>\n      <td>14639.0</td>\n      <td>successful</td>\n      <td>2018</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>100 Thousand and under</td>\n    </tr>\n    <tr>\n      <th>17855</th>\n      <td>99924900</td>\n      <td>The Space Hobo Bottlecap Divination Board</td>\n      <td>USD</td>\n      <td>art</td>\n      <td>2017-01-01 18:50:39</td>\n      <td>2017-01-16 20:00:00</td>\n      <td>2500.0</td>\n      <td>US</td>\n      <td>6636.0</td>\n      <td>successful</td>\n      <td>2017</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>100 Thousand and under</td>\n    </tr>\n  </tbody>\n</table>\n<p>17856 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardised_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab57f5-2737-4e8e-a009-9fbbe4bc12ae",
   "metadata": {},
   "source": [
    "## Unit Tests on Standardised Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b92a7-ed9d-4119-8ee2-53fb927ee20e",
   "metadata": {},
   "source": [
    "##### Create a SparkDFDataset instance of standardised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97db58f2-5e76-40a3-8fea-b7bc453e95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardised_test_df = SparkDFDataset(standardised_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1373aca-7699-4536-a000-97504f8301ba",
   "metadata": {},
   "source": [
    "#### Standardised DF Test 1: Check if metric_category is within scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a7400b0-885c-41be-af0b-01da1df7ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories are within scope: PASSED\n"
     ]
    }
   ],
   "source": [
    "test_result = standardised_test_df.expect_column_values_to_be_in_set(\"metric_category\", METRIC_CATEGORIES)\n",
    "\n",
    "print(f\"\"\"Categories are within scope: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bb616-e0b1-45c5-9c94-2af44b7b7bfd",
   "metadata": {},
   "source": [
    "#### Standardised DF Test 2: Check if campaign population is equal to the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc8236e5-fbba-4555-8433-fed71eaccdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 212:=================================================>   (186 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories are within scope: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_result = standardised_test_df.expect_column_values_to_be_in_set(\"pledge_category\", PLEDGE_CATEGORIES)\n",
    "\n",
    "print(f\"\"\"Categories are within scope: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c2ef5-e5ad-4939-99ae-62f95567e23c",
   "metadata": {},
   "source": [
    "#### Standardised DF Test 3: Check if campaign population is equal to the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e1ccafd-9999-4f37-aa67-01e5184e7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row count of standardised_df (17856) is equal to total row count of filtered_df (17856): PASSED\n"
     ]
    }
   ],
   "source": [
    "filtered_total_rows = filtered_test_df.get_row_count()\n",
    "test_result = standardised_test_df.expect_table_row_count_to_equal(filtered_total_rows)\n",
    "\n",
    "print(f\"\"\"Total row count of standardised_df ({test_result.result['observed_value']}) \\\n",
    "is equal to total row count of filtered_df ({filtered_total_rows}): \\\n",
    "{'PASSED' if test_result.result['observed_value'] == filtered_total_rows else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b4c347-c605-4b9c-b3d7-5d749774d2b7",
   "metadata": {},
   "source": [
    "## Generate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532979e-d137-4729-a94c-bbbb93ee6ce0",
   "metadata": {},
   "source": [
    "### Business Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0643d2-4eff-4dbe-81e7-f1ac335f5702",
   "metadata": {},
   "source": [
    "##### Metric #1: Count Number of successful campaigns for each metric category and pledge category per assessment year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d47636-cbc0-422e-9bdb-57a9c5db6bff",
   "metadata": {},
   "source": [
    "### Generate SQL to produce Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3f73fee-f266-4d3d-b661-dfcf52e5f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_campaigns_df = spark.sql(f\"\"\"\n",
    "    SELECT assessment_year,\n",
    "           metric_category,\n",
    "           pledge_category,\n",
    "           count(id) total_successful_campaigns\n",
    "    FROM STANDARDISED_CAMPAIGNS\n",
    "    GROUP BY assessment_year,\n",
    "            metric_category,\n",
    "            pledge_category\n",
    "    ORDER BY assessment_year,\n",
    "            metric_category,\n",
    "            pledge_category\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef0f15c8-6ca0-4507-a904-ecda803b07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_campaigns_df.createOrReplaceTempView(\"SUCCESSFUL_CAMPAIGNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cac8a764-6eb3-4709-8bd6-51dc76d2e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "   assessment_year                    metric_category  \\\n0             2017  art, crafts, photography & design   \n1             2017  art, crafts, photography & design   \n2             2017  art, crafts, photography & design   \n3             2017  art, crafts, photography & design   \n4             2017    comics, publishing & journalism   \n5             2017    comics, publishing & journalism   \n6             2017                    dance & theater   \n7             2017                               food   \n8             2017                               food   \n9             2017                               food   \n10            2017                 games & technology   \n11            2017                 games & technology   \n12            2017                 games & technology   \n13            2017                 games & technology   \n14            2017                 games & technology   \n15            2017                music, film & video   \n16            2017                music, film & video   \n17            2017                music, film & video   \n18            2017                music, film & video   \n19            2018  art, crafts, photography & design   \n20            2018  art, crafts, photography & design   \n21            2018  art, crafts, photography & design   \n22            2018  art, crafts, photography & design   \n23            2018    comics, publishing & journalism   \n24            2018    comics, publishing & journalism   \n25            2018    comics, publishing & journalism   \n26            2018                    dance & theater   \n27            2018                    dance & theater   \n28            2018                               food   \n29            2018                               food   \n30            2018                               food   \n31            2018                 games & technology   \n32            2018                 games & technology   \n33            2018                 games & technology   \n34            2018                 games & technology   \n35            2018                music, film & video   \n36            2018                music, film & video   \n37            2018                music, film & video   \n\n                          pledge_category  total_successful_campaigns  \n0                  100 Thousand and under                        1319  \n1         Between 1 Million and 5 Million                           2  \n2   Between 100 Thousand and 500 Thousand                          11  \n3      Between 500 Thousand and 1 Million                           3  \n4                  100 Thousand and under                        1914  \n5   Between 100 Thousand and 500 Thousand                          22  \n6                  100 Thousand and under                         468  \n7                  100 Thousand and under                         620  \n8         Between 1 Million and 5 Million                           1  \n9   Between 100 Thousand and 500 Thousand                           6  \n10                 100 Thousand and under                         983  \n11                     5 Million and over                           1  \n12        Between 1 Million and 5 Million                          25  \n13  Between 100 Thousand and 500 Thousand                         183  \n14     Between 500 Thousand and 1 Million                          27  \n15                 100 Thousand and under                        2370  \n16        Between 1 Million and 5 Million                           1  \n17  Between 100 Thousand and 500 Thousand                          29  \n18     Between 500 Thousand and 1 Million                           1  \n19                 100 Thousand and under                        2062  \n20        Between 1 Million and 5 Million                          12  \n21  Between 100 Thousand and 500 Thousand                         104  \n22     Between 500 Thousand and 1 Million                          22  \n23                 100 Thousand and under                        2334  \n24  Between 100 Thousand and 500 Thousand                          27  \n25     Between 500 Thousand and 1 Million                           2  \n26                 100 Thousand and under                         448  \n27  Between 100 Thousand and 500 Thousand                           3  \n28                 100 Thousand and under                         564  \n29  Between 100 Thousand and 500 Thousand                           9  \n30     Between 500 Thousand and 1 Million                           2  \n31                 100 Thousand and under                        1445  \n32        Between 1 Million and 5 Million                          27  \n33  Between 100 Thousand and 500 Thousand                         229  \n34     Between 500 Thousand and 1 Million                          34  \n35                 100 Thousand and under                        2504  \n36  Between 100 Thousand and 500 Thousand                          40  \n37     Between 500 Thousand and 1 Million                           2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>assessment_year</th>\n      <th>metric_category</th>\n      <th>pledge_category</th>\n      <th>total_successful_campaigns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>100 Thousand and under</td>\n      <td>1319</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>Between 1 Million and 5 Million</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>100 Thousand and under</td>\n      <td>1914</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2017</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2017</td>\n      <td>dance &amp; theater</td>\n      <td>100 Thousand and under</td>\n      <td>468</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2017</td>\n      <td>food</td>\n      <td>100 Thousand and under</td>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2017</td>\n      <td>food</td>\n      <td>Between 1 Million and 5 Million</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2017</td>\n      <td>food</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>100 Thousand and under</td>\n      <td>983</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>5 Million and over</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>Between 1 Million and 5 Million</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2017</td>\n      <td>games &amp; technology</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2017</td>\n      <td>music, film &amp; video</td>\n      <td>100 Thousand and under</td>\n      <td>2370</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2017</td>\n      <td>music, film &amp; video</td>\n      <td>Between 1 Million and 5 Million</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2017</td>\n      <td>music, film &amp; video</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2017</td>\n      <td>music, film &amp; video</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2018</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>100 Thousand and under</td>\n      <td>2062</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2018</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>Between 1 Million and 5 Million</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2018</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2018</td>\n      <td>art, crafts, photography &amp; design</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2018</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>100 Thousand and under</td>\n      <td>2334</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2018</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2018</td>\n      <td>comics, publishing &amp; journalism</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2018</td>\n      <td>dance &amp; theater</td>\n      <td>100 Thousand and under</td>\n      <td>448</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2018</td>\n      <td>dance &amp; theater</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2018</td>\n      <td>food</td>\n      <td>100 Thousand and under</td>\n      <td>564</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2018</td>\n      <td>food</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2018</td>\n      <td>food</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2018</td>\n      <td>games &amp; technology</td>\n      <td>100 Thousand and under</td>\n      <td>1445</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2018</td>\n      <td>games &amp; technology</td>\n      <td>Between 1 Million and 5 Million</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2018</td>\n      <td>games &amp; technology</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>229</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2018</td>\n      <td>games &amp; technology</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2018</td>\n      <td>music, film &amp; video</td>\n      <td>100 Thousand and under</td>\n      <td>2504</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2018</td>\n      <td>music, film &amp; video</td>\n      <td>Between 100 Thousand and 500 Thousand</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2018</td>\n      <td>music, film &amp; video</td>\n      <td>Between 500 Thousand and 1 Million</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successful_campaigns_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9fd53-88e8-4354-8a20-c01accce9eed",
   "metadata": {},
   "source": [
    "## Unit Tests on Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58da25-42b7-470f-a241-4713eab97dd6",
   "metadata": {},
   "source": [
    "##### Create a SparkDFDataset instance of successful_campaigns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04810607-b8e4-481e-ae0b-c1ceac19a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_campaigns_df_test_df = SparkDFDataset(successful_campaigns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa39409-8918-4c6c-943a-97511abfcb8a",
   "metadata": {},
   "source": [
    "#### Final Metric DF Test 1: Check if metric_category and pledge_category pair is unique for each assessment year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db231015-fbfa-4d6e-b6a7-33e4e4e7aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_category column is unique for each assessment year: PASSED\n"
     ]
    }
   ],
   "source": [
    "test_result = successful_campaigns_df_test_df.expect_compound_columns_to_be_unique([\"assessment_year\",\"metric_category\",\"pledge_category\"])\n",
    "\n",
    "print(f\"\"\"metric_category column is unique for each assessment year: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b3944-c623-4604-b32e-2a689249cb31",
   "metadata": {},
   "source": [
    "#### Final Metric DF Test 2: Check if sum total of campaigns in metrics dataset is equal to total campaigns in standardised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8afa33a-3f43-42e6-a639-e588eaf88c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of campaigns in metrics dataset (17856) is equal to total rows in standardised dataset (17856): PASSED\n"
     ]
    }
   ],
   "source": [
    "standardised_total_rows = standardised_test_df.get_row_count()\n",
    "test_result = successful_campaigns_df_test_df.expect_column_sum_to_be_between('total_successful_campaigns', \n",
    "                                                                              standardised_total_rows, standardised_total_rows)\n",
    "\n",
    "print(f\"\"\"Total sum of campaigns in metrics dataset ({test_result.result['observed_value']}) \\\n",
    "is equal to total rows in standardised dataset ({standardised_total_rows}): \\\n",
    "{'PASSED' if test_result.result['observed_value'] ==  standardised_total_rows else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47dff0e-d923-4963-aeb6-36388b6bc22f",
   "metadata": {},
   "source": [
    "## Integration Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c80b475d-a587-414a-ade4-efe2336731e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Raw dataset validations: False; 52.63157894736842 successful\n",
      "2. Filtered dataset validations: True; 100.0 successful\n",
      "3. Standardised dataset validations: True; 100.0 successful\n",
      "4. Metrics dataset validations: True; 100.0 successful\n"
     ]
    }
   ],
   "source": [
    "raw_test_df_validation = raw_test_df.validate()\n",
    "print(f\"\"\"1. Raw dataset validations: {raw_test_df_validation.success}; {raw_test_df_validation.statistics['success_percent']} successful\"\"\")\n",
    "filtered_test_df_validation = filtered_test_df.validate()\n",
    "print(f\"\"\"2. Filtered dataset validations: {filtered_test_df_validation.success}; {filtered_test_df_validation.statistics['success_percent']} successful\"\"\")\n",
    "standardised_test_df_validation = standardised_test_df.validate()\n",
    "print(f\"\"\"3. Standardised dataset validations: {standardised_test_df_validation.success}; {standardised_test_df_validation.statistics['success_percent']} successful\"\"\")\n",
    "successful_campaigns_df_test_df_validation = successful_campaigns_df_test_df.validate()\n",
    "print(f\"\"\"4. Metrics dataset validations: {successful_campaigns_df_test_df_validation.success}; {successful_campaigns_df_test_df_validation.statistics['success_percent']} successful\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c6ae2-9d3b-421b-87f3-01cb89f50f12",
   "metadata": {},
   "source": [
    "## Custom Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e595a49f-7e01-47f2-aad5-e9e5b9f4dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.dataset import MetaSparkDFDataset\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83452d84-e90d-4547-a286-ac935669a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSparkDFDataset(SparkDFDataset):\n",
    "    _data_asset_type = \"CustomSparkDFDataset\"\n",
    "    \n",
    "    @MetaSparkDFDataset.column_aggregate_expectation\n",
    "    def expect_column_max_to_be_less_than(\n",
    "        self,\n",
    "        column,\n",
    "        value,\n",
    "        strict=False,\n",
    "        parse_strings_as_datetimes=False,\n",
    "        output_strftime_format=None,\n",
    "        result_format=None,\n",
    "        include_config=True,\n",
    "        catch_exceptions=None,\n",
    "        meta=None,\n",
    "    ):\n",
    "        if parse_strings_as_datetimes:\n",
    "            if value:\n",
    "                value = parse(value)\n",
    "\n",
    "        column_max = self.get_column_max(column, parse_strings_as_datetimes)       \n",
    "        if isinstance(column_max, datetime):\n",
    "            try:\n",
    "                value = parse(value)\n",
    "            except (ValueError, TypeError) as e:\n",
    "                pass\n",
    "\n",
    "        success = column_max < value if strict else column_max <= value\n",
    "        \n",
    "        if parse_strings_as_datetimes:\n",
    "            if output_strftime_format:\n",
    "                column_max = datetime.strftime(column_max, output_strftime_format)\n",
    "            else:\n",
    "                column_max = str(column_max)\n",
    "\n",
    "        return {\"success\": success, \"result\": {\"observed_value\": column_max}}  \n",
    "    \n",
    "    @MetaSparkDFDataset.column_aggregate_expectation\n",
    "    def expect_column_min_to_be_more_than(\n",
    "        self,\n",
    "        column,\n",
    "        value,\n",
    "        strict=False,\n",
    "        parse_strings_as_datetimes=False,\n",
    "        output_strftime_format=None,\n",
    "        result_format=None,\n",
    "        include_config=True,\n",
    "        catch_exceptions=None,\n",
    "        meta=None,\n",
    "    ):\n",
    "        if parse_strings_as_datetimes:\n",
    "            if value:\n",
    "                value = parse(value)\n",
    "\n",
    "        column_min = self.get_column_min(column, parse_strings_as_datetimes)       \n",
    "        if isinstance(column_min, datetime):\n",
    "            try:\n",
    "                value = parse(value)\n",
    "            except (ValueError, TypeError) as e:\n",
    "                pass\n",
    "        \n",
    "        success = column_min > value if strict else column_min >= value\n",
    "        \n",
    "        if parse_strings_as_datetimes:\n",
    "            if output_strftime_format:\n",
    "                column_min = datetime.strftime(column_min, output_strftime_format)\n",
    "            else:\n",
    "                column_min = str(column_min)\n",
    "\n",
    "        return {\"success\": success, \"result\": {\"observed_value\": column_min}}      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23769fc1",
   "metadata": {},
   "source": [
    "#### Filtered DF Custom Test 1: Check if earliest launch_at date is not later than the period_end_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f47770f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  assessment_year period_start_dt period_end_dt\n0            2017      2016-07-01    2017-06-30\n1            2018      2017-07-01    2018-06-30",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>assessment_year</th>\n      <th>period_start_dt</th>\n      <th>period_end_dt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017</td>\n      <td>2016-07-01</td>\n      <td>2017-06-30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018</td>\n      <td>2017-07-01</td>\n      <td>2018-06-30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ca6b9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'2017': <__main__.CustomSparkDFDataset at 0x7f29b858c520>,\n '2018': <__main__.CustomSparkDFDataset at 0x7f29b858c5e0>}"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_dataset_by_year = {}\n",
    "for yr in ASSESSMENT_YEAR:\n",
    "    ge_dataset_by_year[yr] = CustomSparkDFDataset(filtered_df.where(f\"assessment_year = {yr}\"))\n",
    "ge_dataset_by_year    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43bb3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_end_dt(yr):\n",
    "    year_filter = ay_df[\"assessment_year\"]==yr\n",
    "    end_dt = ay_df.loc[year_filter].period_end_dt.item()\n",
    "    return datetime.strftime(datetime.strptime(end_dt, \"%Y-%m-%d\") + timedelta(days=1), \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0536f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AY 2017 latest launched_at 2017-06-21 20:23:32 < period_end_dt 2017-07-01: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 308:===================================================> (194 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AY 2018 latest launched_at 2018-06-30 23:01:04 < period_end_dt 2018-07-01: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for yr in ASSESSMENT_YEAR:\n",
    "    period_end_dt = get_period_end_dt(yr)   \n",
    "    test_result = ge_dataset_by_year[yr]\\\n",
    "                    .expect_column_max_to_be_less_than(\"launched_at\", \n",
    "                                                       period_end_dt, \n",
    "                                                       parse_strings_as_datetimes=True, \n",
    "                                                       strict=True)\n",
    "    print(f\"\"\"AY {yr} latest launched_at {test_result.result['observed_value']}\"\"\", \n",
    "          f\"\"\"< period_end_dt {period_end_dt}: {'PASSED' if test_result.success else 'FAILED'}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb004d",
   "metadata": {},
   "source": [
    "#### Filtered DF Custom Test 2: Check if earliest campaign deadline is past or falls on the period_start_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c7da5ec-242e-4f83-b64c-c745ce02d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_start_dt(yr):\n",
    "    year_filter = ay_df[\"assessment_year\"]==yr\n",
    "    return ay_df.loc[year_filter].period_start_dt.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31e04f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AY 2017 earliest deadline 2016-07-01 00:00:00 >= period_start_dt 2016-07-01: PASSED\n",
      "AY 2018 earliest deadline 2017-07-01 00:00:00 >= period_start_dt 2017-07-01: PASSED\n"
     ]
    }
   ],
   "source": [
    "for yr in ASSESSMENT_YEAR:\n",
    "    period_start_dt = get_period_start_dt(yr)    \n",
    "    test_result = ge_dataset_by_year[yr]\\\n",
    "                    .expect_column_min_to_be_more_than(\"deadline\", \n",
    "                                                       period_start_dt, \n",
    "                                                       parse_strings_as_datetimes=True)\n",
    "    print(f\"\"\"AY {yr} earliest deadline {test_result.result['observed_value']}\"\"\", \n",
    "          f\"\"\">= period_start_dt {period_start_dt}: {'PASSED' if test_result.success else 'FAILED'}\"\"\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005616fb-6f4b-4c61-9127-9b80dc94362c",
   "metadata": {},
   "source": [
    "### Integration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4562edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset for year 2017 validations: True; 100.0 successful\n",
      "Filtered dataset for year 2018 validations: True; 100.0 successful\n"
     ]
    }
   ],
   "source": [
    "for yr, yearly_df in ge_dataset_by_year.items():\n",
    "    yearly_df_validation = yearly_df.validate()\n",
    "    print(f\"\"\"Filtered dataset for year {yr} validations: {yearly_df_validation.success}; {yearly_df_validation.statistics['success_percent']} successful\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
