{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tutorial 2\n",
    "\n",
    "In tutorial 1, we used the CLI and generated notebook to create data source, expectation suites and check points. In this tutorial, we will try to create a notebook by ourselves and do all the actions with one single notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.data_context.types.resource_identifiers import (\n",
    "    ExpectationSuiteIdentifier,\n",
    ")\n",
    "from great_expectations.exceptions import DataContextError\n",
    "import great_expectations as ge\n",
    "from great_expectations.cli.datasource import sanitize_yaml_and_save_datasource, check_if_datasource_name_exists\n",
    "from ruamel.yaml import YAML"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 0. Get the project context\n",
    "\n",
    "To get the project context, we called the get_context() method. This works only if the notebook is located inside the greate expectation project root directory. Because the source code of get_context() is just call the DataContext() without argument\n",
    "\n",
    "```python\n",
    "def get_context():\n",
    "    from great_expectations.data_context.data_context import DataContext\n",
    "\n",
    "    return DataContext()\n",
    "```\n",
    "If you want to work anywhere outside the project, you need to create a context by using the DataContext class. Below code is an\n",
    "example.\n",
    "\n",
    "```python\n",
    "ge_project_root_dir=\"../great_expectations_validation/great_expectations\"\n",
    "data_context = ge.data_context.DataContext(context_root_dir=ge_project_root_dir)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "context = ge.get_context()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The context of the project is stored in the **great_expectations.yml**. When you load context, you read data from it. When you save datasource, expectations, checkpoints, you just add new section in the yaml file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Create a new pandas Datasource\n",
    "Here we create a file based datasource"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: pengfei_test\n",
      "class_name: Datasource\n",
      "execution_engine:\n",
      "  class_name: PandasExecutionEngine\n",
      "data_connectors:\n",
      "  default_inferred_data_connector_name:\n",
      "    class_name: InferredAssetFilesystemDataConnector\n",
      "    base_directory: ../../data\n",
      "    default_regex:\n",
      "      group_names:\n",
      "        - data_asset_name\n",
      "      pattern: (.*)\n",
      "  default_runtime_data_connector_name:\n",
      "    class_name: RuntimeDataConnector\n",
      "    batch_identifiers:\n",
      "      - default_identifier_name\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can name it as you want\n",
    "datasource_name = \"pengfei_test\"\n",
    "\n",
    "my_datasource_yaml = f\"\"\"\n",
    "name: {datasource_name}\n",
    "class_name: Datasource\n",
    "execution_engine:\n",
    "  class_name: PandasExecutionEngine\n",
    "data_connectors:\n",
    "  default_inferred_data_connector_name:\n",
    "    class_name: InferredAssetFilesystemDataConnector\n",
    "    base_directory: ../../data\n",
    "    default_regex:\n",
    "      group_names:\n",
    "        - data_asset_name\n",
    "      pattern: (.*)\n",
    "  default_runtime_data_connector_name:\n",
    "    class_name: RuntimeDataConnector\n",
    "    batch_identifiers:\n",
    "      - default_identifier_name\n",
    "\"\"\"\n",
    "print(my_datasource_yaml)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Test if your data source configuration is valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: PandasExecutionEngine\n",
      "Data Connectors:\n",
      "\tdefault_inferred_data_connector_name : InferredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (2 of 2):\n",
      "\t\tadult.csv (1 of 1): ['adult.csv']\n",
      "\t\tadult_with_duplicates.csv (1 of 1): ['adult_with_duplicates.csv']\n",
      "\n",
      "\tUnmatched data_references (0 of 0):[]\n",
      "\n",
      "\tdefault_runtime_data_connector_name:RuntimeDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (0 of 0):\n",
      "\t\tNote : RuntimeDataConnector will not have data_asset_names until they are passed in through RuntimeBatchRequest\n",
      "\n",
      "\tUnmatched data_references (0 of 0): []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<great_expectations.datasource.new_datasource.Datasource at 0x7fb5a02e2f10>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.test_yaml_config(yaml_config=my_datasource_yaml)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 save the datasource"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "sanitize_yaml_and_save_datasource(context, my_datasource_yaml, overwrite_existing=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 1.3 List existing datasource"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'execution_engine': {'class_name': 'PandasExecutionEngine',\n   'module_name': 'great_expectations.execution_engine'},\n  'class_name': 'Datasource',\n  'module_name': 'great_expectations.datasource',\n  'data_connectors': {'default_inferred_data_connector_name': {'base_directory': '../../data',\n    'module_name': 'great_expectations.datasource.data_connector',\n    'default_regex': {'group_names': ['data_asset_name'], 'pattern': '(.*)'},\n    'class_name': 'InferredAssetFilesystemDataConnector'},\n   'default_runtime_data_connector_name': {'batch_identifiers': ['default_identifier_name'],\n    'module_name': 'great_expectations.datasource.data_connector',\n    'class_name': 'RuntimeDataConnector'}},\n  'name': 'census_income_validation'},\n {'execution_engine': {'class_name': 'PandasExecutionEngine',\n   'module_name': 'great_expectations.execution_engine'},\n  'class_name': 'Datasource',\n  'module_name': 'great_expectations.datasource',\n  'data_connectors': {'default_inferred_data_connector_name': {'base_directory': '../../data',\n    'module_name': 'great_expectations.datasource.data_connector',\n    'default_regex': {'group_names': ['data_asset_name'], 'pattern': '(.*)'},\n    'class_name': 'InferredAssetFilesystemDataConnector'},\n   'default_runtime_data_connector_name': {'batch_identifiers': ['default_identifier_name'],\n    'module_name': 'great_expectations.datasource.data_connector',\n    'class_name': 'RuntimeDataConnector'}},\n  'name': 'pengfei_test'}]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.list_datasources()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create or Edit expectation suits\n",
    "\n",
    "Below code takes an **expectation suit name** as input, if it exists in the project, it returns the e"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ExpectationSuite \"pengfei.test1\".\n"
     ]
    }
   ],
   "source": [
    "expectation_suite_name = \"pengfei.test1\"\n",
    "\n",
    "\n",
    "try:\n",
    "    suite = context.get_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "    print(\n",
    "        f'Loaded ExpectationSuite \"{suite.expectation_suite_name}\" containing {len(suite.expectations)} expectations.'\n",
    "    )\n",
    "except DataContextError:\n",
    "    suite = context.create_expectation_suite(\n",
    "        expectation_suite_name=expectation_suite_name\n",
    "    )\n",
    "    print(f'Created ExpectationSuite \"{suite.expectation_suite_name}\".')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.1 Add expectations to the expectation suite\n",
    "\n",
    "After getting the instance of the expectation suite, we can and need to add expectations(validation rules) to the suite.\n",
    "Below is an example, we add a rule that verify column age can not have null values.\n",
    "\n",
    "For now, if the expectation suite already contains expectations(validation rules), we can't remove them by using the suite object. We can only add new rules.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"kwargs\": {\"column\": \"age\"}, \"meta\": {}, \"expectation_type\": \"expect_column_values_to_not_be_null\"}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule, it's a dict fill with key/value\n",
    "expectation_configuration = ExpectationConfiguration(\n",
    "    **{\n",
    "        \"meta\": {},\n",
    "        \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
    "        \"kwargs\": {\"column\": \"age\"},\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=expectation_configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 Save the expectation suite to the project context\n",
    "\n",
    "After you save the expectation, it will create a new directory in the folder \"expectations\". The name of the created directory is the first part of the expectation suite name (i.e. pengfei). The json file in the directory (i.e. test1.json) is the actual file that contains all the expectations (validation rules)\n",
    "\n",
    "```text\n",
    "├── great_expectations\n",
    "│         ├── checkpoints\n",
    "│         ├── expectations\n",
    "│                   ├── census_income_expectation_suite\n",
    "│                   └── pengfei\n",
    "|                         |__test1.json\n",
    "\n",
    "│         ├── plugins\n",
    "│         └── uncommitted\n",
    "└── README.md\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "context.save_expectation_suite(expectation_suite=suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "# we can get an identifier by using the name of expectation suite\n",
    "suite_identifier = ExpectationSuiteIdentifier(expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "# use the below command will use the config in the expectation folders to generate a web page that contains the\n",
    "# information of the newly created expectation suite\n",
    "context.build_data_docs(resource_identifiers=[suite_identifier])\n",
    "\n",
    "# open the web page in a browser\n",
    "context.open_data_docs(resource_identifier=suite_identifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should see the below page in your browser\n",
    "\n",
    "![Expectation_ui](../images/expectations_validation_rule.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Creat checkpoint\n",
    "\n",
    "We have defined data source and validation rules. Now we need to associate the data source and validation rules togethor. For this purpose, we introduce a new concept checkpoint. Checkpoint will apply a list of expectation sets on a list of dataset, then based on the result, it will execute a list of actions (e.g. save result to data-docs, send alert to slack, etc.)\n",
    "For more information, you can visit the [official doc](https://docs.greatexpectations.io/docs/reference/checkpoints_and_actions)\n",
    "\n",
    "In this tutorial, we will use the **SimpleCheckpoint class** to create a checkpoint. It provides a basic set of actions (e.g. store Validation Result, store evaluation parameters, update Data Docs, and optionally, send a Slack notification). So we don't need to declare an action_list in the checkpoint configuration.\n",
    "\n",
    "## 3.1 Specify your checkpoint config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: census_income_checkpoint\n",
      "config_version: 1.0\n",
      "class_name: SimpleCheckpoint\n",
      "run_name_template: \"%Y%m%d-%H%M%S-my-run-name-template\"\n",
      "validations:\n",
      "  - batch_request:\n",
      "      datasource_name: pengfei_test\n",
      "      data_connector_name: default_inferred_data_connector_name\n",
      "      data_asset_name: adult_with_duplicates.csv\n",
      "      data_connector_query:\n",
      "        index: -1\n",
      "    expectation_suite_name: pengfei.test1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yaml = YAML()\n",
    "\n",
    "# Use yaml to configure a checkpoint\n",
    "my_checkpoint_name = \"pengfei_test_checkpoint\"\n",
    "\n",
    "checkpoint_config = f\"\"\"\n",
    "name: {my_checkpoint_name}\n",
    "config_version: 1.0\n",
    "class_name: SimpleCheckpoint\n",
    "run_name_template: \"%Y%m%d-%H%M%S-my-run-name-template\"\n",
    "validations:\n",
    "  - batch_request:\n",
    "      datasource_name: pengfei_test\n",
    "      data_connector_name: default_inferred_data_connector_name\n",
    "      data_asset_name: adult_with_duplicates.csv\n",
    "      data_connector_query:\n",
    "        index: -1\n",
    "    expectation_suite_name: pengfei.test1\n",
    "\"\"\"\n",
    "\n",
    "# preview the checkpoint config\n",
    "print(checkpoint_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will explain the above config yaml file line by line,\n",
    "\n",
    "- class_name: is the checkpoint class name\n",
    "- run_name_template: the name of the checkpoint run result after each validation. So you should include time stamp in it to make it easy to track\n",
    "\n",
    "- validations: defines the association between data source and validation rules\n",
    "  - batch_request:\n",
    "      datasource_name: name of your datasource\n",
    "      data_connector_name: default_inferred_data_connector_name\n",
    "      data_asset_name: target file name in your data source\n",
    "      data_connector_query:\n",
    "        index: -1\n",
    "    expectation_suite_name: the name of your expectation suite\n",
    "\n",
    "\n",
    "If you are not sure about the names, you can use below command to get the available data source and expectation suite"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'census_income_validation': {'default_inferred_data_connector_name': ['adult.csv',\n",
      "                                                                       'adult_with_duplicates.csv'],\n",
      "                              'default_runtime_data_connector_name': []},\n",
      " 'pengfei_test': {'default_inferred_data_connector_name': ['adult.csv',\n",
      "                                                           'adult_with_duplicates.csv'],\n",
      "                  'default_runtime_data_connector_name': []}}\n",
      "['census_income_expectation_suite.test1', 'pengfei.test1']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# if you don't know the data asset name in your project, you can use below command to get the available asset name list\n",
    "pprint(context.get_available_data_asset_names())\n",
    "\n",
    "# you can also get available expectation suite list\n",
    "pprint(context.list_expectation_suite_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Validate your checkpoint configuration\n",
    "\n",
    "To test your checkpoint, you can use below command. If it's  valid, you should see \"Successfully instantiated SimpleCheckpoint\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a SimpleCheckpoint, since class_name is SimpleCheckpoint\n",
      "{\n",
      "  \"name\": \"census_income_checkpoint\",\n",
      "  \"config_version\": 1.0,\n",
      "  \"template_name\": null,\n",
      "  \"module_name\": \"great_expectations.checkpoint\",\n",
      "  \"class_name\": \"SimpleCheckpoint\",\n",
      "  \"run_name_template\": \"%Y%m%d-%H%M%S-my-run-name-template\",\n",
      "  \"expectation_suite_name\": null,\n",
      "  \"batch_request\": null,\n",
      "  \"action_list\": [\n",
      "    {\n",
      "      \"name\": \"store_validation_result\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreValidationResultAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"store_evaluation_params\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"update_data_docs\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"UpdateDataDocsAction\",\n",
      "        \"site_names\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"evaluation_parameters\": {},\n",
      "  \"runtime_configuration\": {},\n",
      "  \"validations\": [\n",
      "    {\n",
      "      \"batch_request\": {\n",
      "        \"datasource_name\": \"pengfei_test\",\n",
      "        \"data_connector_name\": \"default_inferred_data_connector_name\",\n",
      "        \"data_asset_name\": \"adult_with_duplicates.csv\",\n",
      "        \"data_connector_query\": {\n",
      "          \"index\": -1\n",
      "        }\n",
      "      },\n",
      "      \"expectation_suite_name\": \"pengfei.test1\"\n",
      "    }\n",
      "  ],\n",
      "  \"profilers\": [],\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectation_suite_ge_cloud_id\": null\n",
      "}\n",
      "\tSuccessfully instantiated SimpleCheckpoint\n",
      "\n",
      "\n",
      "Checkpoint class name: SimpleCheckpoint\n"
     ]
    }
   ],
   "source": [
    "my_checkpoint = context.test_yaml_config(yaml_config=checkpoint_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Save your checkpoint\n",
    "If your checkpoint config is valid, you can save it to your project context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"census_income_checkpoint\",\n",
      "  \"config_version\": 1.0,\n",
      "  \"template_name\": null,\n",
      "  \"module_name\": \"great_expectations.checkpoint\",\n",
      "  \"class_name\": \"Checkpoint\",\n",
      "  \"run_name_template\": \"%Y%m%d-%H%M%S-my-run-name-template\",\n",
      "  \"expectation_suite_name\": null,\n",
      "  \"batch_request\": null,\n",
      "  \"action_list\": [\n",
      "    {\n",
      "      \"name\": \"store_validation_result\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreValidationResultAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"store_evaluation_params\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"update_data_docs\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"UpdateDataDocsAction\",\n",
      "        \"site_names\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"evaluation_parameters\": {},\n",
      "  \"runtime_configuration\": {},\n",
      "  \"validations\": [\n",
      "    {\n",
      "      \"batch_request\": {\n",
      "        \"datasource_name\": \"pengfei_test\",\n",
      "        \"data_connector_name\": \"default_inferred_data_connector_name\",\n",
      "        \"data_asset_name\": \"adult_with_duplicates.csv\",\n",
      "        \"data_connector_query\": {\n",
      "          \"index\": -1\n",
      "        }\n",
      "      },\n",
      "      \"expectation_suite_name\": \"pengfei.test1\"\n",
      "    }\n",
      "  ],\n",
      "  \"profilers\": [],\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectation_suite_ge_cloud_id\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<great_expectations.checkpoint.checkpoint.SimpleCheckpoint at 0x7fb576288820>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_checkpoint(**yaml.load(checkpoint_config))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 Run checkpoint and view the output\n",
    "\n",
    "To run the Checkpoint, you can use below command now and review its output in Data Docs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b26d2c7a1ed7497c90cbd67444d18907"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.run_checkpoint(checkpoint_name=my_checkpoint_name)\n",
    "context.open_data_docs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should see below web page\n",
    "![Expectation_checkpoint](../images/expectations_checkpoint.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}