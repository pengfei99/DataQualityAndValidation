{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GE validation demo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.data_context.types.resource_identifiers import (\n",
    "    ExpectationSuiteIdentifier,\n",
    ")\n",
    "from great_expectations.exceptions import DataContextError\n",
    "import great_expectations as ge\n",
    "from great_expectations.cli.datasource import sanitize_yaml_and_save_datasource, check_if_datasource_name_exists\n",
    "from ruamel.yaml import YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# 0. Get the project context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "context = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The context of the project is stored in the **great_expectations.yml**. When you load context, you read data from it. When you save datasource, expectations, checkpoints, you just add new section in the yaml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Create a datasource\n",
    "Unlike tdda, GE is a heavyweight framework, we must load the source data into the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# you can name it as you want\n",
    "datasource_name = \"ge_demo\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: ge_demo\n",
      "class_name: Datasource\n",
      "execution_engine:\n",
      "  class_name: PandasExecutionEngine\n",
      "data_connectors:\n",
      "  default_inferred_data_connector_name:\n",
      "    class_name: InferredAssetFilesystemDataConnector\n",
      "    base_directory: ../../../data\n",
      "    default_regex:\n",
      "      group_names:\n",
      "        - data_asset_name\n",
      "      pattern: (.*)\n",
      "  default_runtime_data_connector_name:\n",
      "    class_name: RuntimeDataConnector\n",
      "    batch_identifiers:\n",
      "      - default_identifier_name\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_datasource_yaml = f\"\"\"\n",
    "name: {datasource_name}\n",
    "class_name: Datasource\n",
    "execution_engine:\n",
    "  class_name: PandasExecutionEngine\n",
    "data_connectors:\n",
    "  default_inferred_data_connector_name:\n",
    "    class_name: InferredAssetFilesystemDataConnector\n",
    "    base_directory: ../../../data\n",
    "    default_regex:\n",
    "      group_names:\n",
    "        - data_asset_name\n",
    "      pattern: (.*)\n",
    "  default_runtime_data_connector_name:\n",
    "    class_name: RuntimeDataConnector\n",
    "    batch_identifiers:\n",
    "      - default_identifier_name\n",
    "\"\"\"\n",
    "print(my_datasource_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 Test if your data source configuration is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: PandasExecutionEngine\n",
      "Data Connectors:\n",
      "\tdefault_inferred_data_connector_name : InferredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (3 of 3):\n",
      "\t\tadult.csv (1 of 1): ['adult.csv']\n",
      "\t\tadult_with_duplicates.csv (1 of 1): ['adult_with_duplicates.csv']\n",
      "\t\tadult_with_header.csv (1 of 1): ['adult_with_header.csv']\n",
      "\n",
      "\tUnmatched data_references (0 of 0):[]\n",
      "\n",
      "\tdefault_runtime_data_connector_name:RuntimeDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (0 of 0):\n",
      "\t\tNote : RuntimeDataConnector will not have data_asset_names until they are passed in through RuntimeBatchRequest\n",
      "\n",
      "\tUnmatched data_references (0 of 0): []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<great_expectations.datasource.new_datasource.Datasource at 0x7eff0db66550>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.test_yaml_config(yaml_config=my_datasource_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 save the datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanitize_yaml_and_save_datasource(context, my_datasource_yaml, overwrite_existing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3 List existing datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'module_name': 'great_expectations.datasource',\n  'execution_engine': {'module_name': 'great_expectations.execution_engine',\n   'class_name': 'PandasExecutionEngine'},\n  'data_connectors': {'default_inferred_data_connector_name': {'module_name': 'great_expectations.datasource.data_connector',\n    'base_directory': '../../../data',\n    'class_name': 'InferredAssetFilesystemDataConnector',\n    'default_regex': {'group_names': ['data_asset_name'], 'pattern': '(.*)'}},\n   'default_runtime_data_connector_name': {'module_name': 'great_expectations.datasource.data_connector',\n    'batch_identifiers': ['default_identifier_name'],\n    'class_name': 'RuntimeDataConnector'}},\n  'class_name': 'Datasource',\n  'name': 'ge_demo'}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.list_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Create custom validation rules\n",
    "\n",
    "In GE, validation rules are called **expectation suit**. We need to create an empty expectation suit, then add rules in it.\n",
    "## 2.1 Create expectation suit\n",
    "\n",
    "Below code takes an **expectation suit name** as input, if **expectation suit name** exists in the project, it returns the existing expectation suit. Otherwise, it will create an empty one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ExpectationSuite \"ge_demo.rules\" containing 7 expectations.\n"
     ]
    }
   ],
   "source": [
    "expectation_suite_name = \"ge_demo.rules\"\n",
    "\n",
    "try:\n",
    "    suite = context.get_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "    print(\n",
    "        f'Loaded ExpectationSuite \"{suite.expectation_suite_name}\" containing {len(suite.expectations)} expectations.'\n",
    "    )\n",
    "except DataContextError:\n",
    "    suite = context.create_expectation_suite(\n",
    "        expectation_suite_name=expectation_suite_name\n",
    "    )\n",
    "    print(f'Created ExpectationSuite \"{suite.expectation_suite_name}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Add validation rules to the expectation suite\n",
    "\n",
    "All supported expectations: https://greatexpectations.io/expectations/\n",
    "\n",
    "# Validation rules\n",
    "\n",
    "Table level validation rule:\n",
    "1. Table must have 32603 rows and 15 columns\n",
    "2. Table can't have duplicate rows\n",
    "\n",
    "Column level validation rule:\n",
    "1. Column Age must be a number\n",
    "2. Column Age can't have null\n",
    "3. Column Age must have value between 0 and 120\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"max_value\": 32603, \"min_value\": 32603}, \"expectation_type\": \"expect_table_row_count_to_be_between\"}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to validate row number\n",
    "table_row_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_table_row_count_to_be_between\",\n",
    "      \"kwargs\": {\n",
    "        \"max_value\": 32603,\n",
    "        \"min_value\": 32603\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=table_row_rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"column_list\": [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]}, \"expectation_type\": \"expect_table_columns_to_match_ordered_list\"}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to validate column number, name and order\n",
    "table_column_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_table_columns_to_match_ordered_list\",\n",
    "      \"kwargs\": {\n",
    "        \"column_list\": [\n",
    "          \"age\",\n",
    "          \"workclass\",\n",
    "          \"fnlwgt\",\n",
    "          \"education\",\n",
    "          \"education-num\",\n",
    "          \"marital-status\",\n",
    "          \"occupation\",\n",
    "          \"relationship\",\n",
    "          \"race\",\n",
    "          \"sex\",\n",
    "          \"capital-gain\",\n",
    "          \"capital-loss\",\n",
    "          \"hours-per-week\",\n",
    "          \"native-country\",\n",
    "          \"income\"\n",
    "        ]\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=table_column_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"column_list\": [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]}, \"expectation_type\": \"expect_compound_columns_to_be_unique\"}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to detect duplicate row\n",
    "detect_duplication_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_compound_columns_to_be_unique\",\n",
    "      \"kwargs\": {\n",
    "        \"column_list\": [\n",
    "          \"age\",\n",
    "          \"workclass\",\n",
    "          \"fnlwgt\",\n",
    "          \"education\",\n",
    "          \"education-num\",\n",
    "          \"marital-status\",\n",
    "          \"occupation\",\n",
    "          \"relationship\",\n",
    "          \"race\",\n",
    "          \"sex\",\n",
    "          \"capital-gain\",\n",
    "          \"capital-loss\",\n",
    "          \"hours-per-week\",\n",
    "          \"native-country\",\n",
    "          \"income\"\n",
    "        ]\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=detect_duplication_rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"column\": \"age\", \"regex\": \"[-+]?(\\\\d+$)\"}, \"expectation_type\": \"expect_column_values_to_match_regex\"}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to validate row number\n",
    "age_number_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_column_values_to_match_regex\",\n",
    "      \"kwargs\": {\n",
    "        \"column\": \"age\",\n",
    "        \"regex\": \"^[-+]?\\d+$\"\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=age_number_rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"column\": \"age\"}, \"expectation_type\": \"expect_column_values_to_not_be_null\"}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to validate row number\n",
    "age_no_null_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
    "      \"kwargs\": {\n",
    "        \"column\": \"age\",\n",
    "        # \"mostly\": 0.99\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=age_no_null_rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"column\": \"age\", \"max_value\": 0, \"min_value\": 0}, \"expectation_type\": \"expect_column_min_to_be_between\"}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to validate row number\n",
    "age_min_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_column_min_to_be_between\",\n",
    "      \"kwargs\": {\n",
    "        \"column\": \"age\",\n",
    "        \"max_value\": 0,\n",
    "        \"min_value\": 0\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=age_min_rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{\"meta\": {}, \"kwargs\": {\"column\": \"age\", \"max_value\": 120, \"min_value\": 120}, \"expectation_type\": \"expect_column_max_to_be_between\"}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation rule to validate row number\n",
    "age_max_rule = ExpectationConfiguration(\n",
    "    **{\n",
    "      \"expectation_type\": \"expect_column_max_to_be_between\",\n",
    "      \"kwargs\": {\n",
    "        \"column\": \"age\",\n",
    "        \"max_value\": 120,\n",
    "        \"min_value\": 120\n",
    "      },\n",
    "      \"meta\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "# add the rule to the suite\n",
    "suite.add_expectation(expectation_configuration=age_max_rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.3 Save the expectation suite to the project context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "context.save_expectation_suite(expectation_suite=suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "# we can get an identifier by using the name of expectation suite\n",
    "suite_identifier = ExpectationSuiteIdentifier(expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "# use the below command will use the config in the expectation folders to generate a web page that contains the\n",
    "# information of the newly created expectation suite\n",
    "context.build_data_docs(resource_identifiers=[suite_identifier])\n",
    "\n",
    "# open the web page in a browser\n",
    "context.open_data_docs(resource_identifier=suite_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Creat checkpoint\n",
    "\n",
    "We have defined data source and validation rules. Now we need to associate the data source and validation rules togethor. For this purpose, we introduce a new concept checkpoint. Checkpoint will apply a list of expectation sets on a list of dataset, then based on the result, it will execute a list of actions (e.g. save result to data-docs, send alert to slack, etc.)\n",
    "For more information, you can visit the [official doc](https://docs.greatexpectations.io/docs/reference/checkpoints_and_actions)\n",
    "\n",
    "In this tutorial, we will use the **SimpleCheckpoint class** to create a checkpoint. It provides a basic set of actions (e.g. store Validation Result, store evaluation parameters, update Data Docs, and optionally, send a Slack notification). So we don't need to declare an action_list in the checkpoint configuration.\n",
    "\n",
    "## 3.1 Specify your checkpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource_name: ge_demo\n",
      "expectation_suite_name: ge_demo.rules\n"
     ]
    }
   ],
   "source": [
    "yaml = YAML()\n",
    "\n",
    "# Use yaml to configure a checkpoint\n",
    "ck0_name = \"pengfei_demo_checkpoint\"\n",
    "print(f\"datasource_name: {datasource_name}\")\n",
    "dataset_name= \"adult_with_duplicates.csv\"\n",
    "print(f\"expectation_suite_name: {expectation_suite_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: pengfei_demo_checkpoint\n",
      "config_version: 1.0\n",
      "class_name: SimpleCheckpoint\n",
      "run_name_template: \"%Y%m%d-%H%M%S-my-run-name-template\"\n",
      "validations:\n",
      "  - batch_request:\n",
      "      datasource_name: ge_demo\n",
      "      data_connector_name: default_inferred_data_connector_name\n",
      "      data_asset_name: adult_with_duplicates.csv\n",
      "      data_connector_query:\n",
      "        index: -1\n",
      "    expectation_suite_name: ge_demo.rules\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint_config = f\"\"\"\n",
    "name: {ck0_name}\n",
    "config_version: 1.0\n",
    "class_name: SimpleCheckpoint\n",
    "run_name_template: \"%Y%m%d-%H%M%S-my-run-name-template\"\n",
    "validations:\n",
    "  - batch_request:\n",
    "      datasource_name: {datasource_name}\n",
    "      data_connector_name: default_inferred_data_connector_name\n",
    "      data_asset_name: {dataset_name}\n",
    "      data_connector_query:\n",
    "        index: -1\n",
    "    expectation_suite_name: {expectation_suite_name}\n",
    "\"\"\"\n",
    "\n",
    "# preview the checkpoint config\n",
    "print(checkpoint_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available data source list: \n",
      "{'ge_demo': {'default_inferred_data_connector_name': ['adult_with_duplicates.csv', 'adult.csv', 'adult_with_header.csv'], 'default_runtime_data_connector_name': []}}\n",
      "available data source list: \n",
      "['ge_demo.rules']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# if you don't know the data asset name in your project, you can use below command to get the available asset name list\n",
    "print(f\"available data source list: \\n{context.get_available_data_asset_names()}\")\n",
    "\n",
    "# you can also get available expectation suite list\n",
    "print(f\"available data source list: \\n{context.list_expectation_suite_names()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Validate your checkpoint configuration\n",
    "\n",
    "To test your checkpoint, you can use below command. If it's  valid, you should see \"Successfully instantiated SimpleCheckpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a SimpleCheckpoint, since class_name is SimpleCheckpoint\n",
      "{\n",
      "  \"name\": \"pengfei_demo_checkpoint\",\n",
      "  \"config_version\": 1.0,\n",
      "  \"template_name\": null,\n",
      "  \"module_name\": \"great_expectations.checkpoint\",\n",
      "  \"class_name\": \"SimpleCheckpoint\",\n",
      "  \"run_name_template\": \"%Y%m%d-%H%M%S-my-run-name-template\",\n",
      "  \"expectation_suite_name\": null,\n",
      "  \"batch_request\": null,\n",
      "  \"action_list\": [\n",
      "    {\n",
      "      \"name\": \"store_validation_result\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreValidationResultAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"store_evaluation_params\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"update_data_docs\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"UpdateDataDocsAction\",\n",
      "        \"site_names\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"evaluation_parameters\": {},\n",
      "  \"runtime_configuration\": {},\n",
      "  \"validations\": [\n",
      "    {\n",
      "      \"batch_request\": {\n",
      "        \"datasource_name\": \"ge_demo\",\n",
      "        \"data_connector_name\": \"default_inferred_data_connector_name\",\n",
      "        \"data_asset_name\": \"adult_with_duplicates.csv\",\n",
      "        \"data_connector_query\": {\n",
      "          \"index\": -1\n",
      "        }\n",
      "      },\n",
      "      \"expectation_suite_name\": \"ge_demo.rules\"\n",
      "    }\n",
      "  ],\n",
      "  \"profilers\": [],\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectation_suite_ge_cloud_id\": null\n",
      "}\n",
      "\tSuccessfully instantiated SimpleCheckpoint\n",
      "\n",
      "\n",
      "Checkpoint class name: SimpleCheckpoint\n"
     ]
    }
   ],
   "source": [
    "my_checkpoint = context.test_yaml_config(yaml_config=checkpoint_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 Save your checkpoint\n",
    "If your checkpoint config is valid, you can save it to your project context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"pengfei_demo_checkpoint\",\n",
      "  \"config_version\": 1.0,\n",
      "  \"template_name\": null,\n",
      "  \"module_name\": \"great_expectations.checkpoint\",\n",
      "  \"class_name\": \"Checkpoint\",\n",
      "  \"run_name_template\": \"%Y%m%d-%H%M%S-my-run-name-template\",\n",
      "  \"expectation_suite_name\": null,\n",
      "  \"batch_request\": null,\n",
      "  \"action_list\": [\n",
      "    {\n",
      "      \"name\": \"store_validation_result\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreValidationResultAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"store_evaluation_params\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"update_data_docs\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"UpdateDataDocsAction\",\n",
      "        \"site_names\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"evaluation_parameters\": {},\n",
      "  \"runtime_configuration\": {},\n",
      "  \"validations\": [\n",
      "    {\n",
      "      \"batch_request\": {\n",
      "        \"datasource_name\": \"ge_demo\",\n",
      "        \"data_connector_name\": \"default_inferred_data_connector_name\",\n",
      "        \"data_asset_name\": \"adult_with_duplicates.csv\",\n",
      "        \"data_connector_query\": {\n",
      "          \"index\": -1\n",
      "        }\n",
      "      },\n",
      "      \"expectation_suite_name\": \"ge_demo.rules\"\n",
      "    }\n",
      "  ],\n",
      "  \"profilers\": [],\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectation_suite_ge_cloud_id\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<great_expectations.checkpoint.checkpoint.SimpleCheckpoint at 0x7fca5c4a3be0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_checkpoint(**yaml.load(checkpoint_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4 Run checkpoint and view the output\n",
    "\n",
    "To run the Checkpoint, you can use below command now and review its output in Data Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Calculating Metrics:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d0a08c6abb3484cb172a00cbffbcde1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An unexpected Exception occurred during data docs rendering.  Because of this error, certain parts of data docs will not be rendered properly and/or may not appear altogether.  Please use the trace, included in this message, to diagnose and repair the underlying issue.  Detailed information follows:\n",
      "            AttributeError: \"'str' object has no attribute 'get'\".  Traceback: \"Traceback (most recent call last):\n",
      "  File \"/home/pliu/.cache/pypoetry/virtualenvs/dataqualityandvalidation-6LYnP9NJ-py3.8/lib/python3.8/site-packages/great_expectations/render/renderer/content_block/validation_results_table_content_block.py\", line 163, in row_generator_fn\n",
      "    unexpected_table_renderer[1](result=result)\n",
      "  File \"/home/pliu/.cache/pypoetry/virtualenvs/dataqualityandvalidation-6LYnP9NJ-py3.8/lib/python3.8/site-packages/great_expectations/render/renderer/renderer.py\", line 13, in inner_func\n",
      "    return renderer_fn(*args, **kwargs)\n",
      "  File \"/home/pliu/.cache/pypoetry/virtualenvs/dataqualityandvalidation-6LYnP9NJ-py3.8/lib/python3.8/site-packages/great_expectations/expectations/expectation.py\", line 539, in _diagnostic_unexpected_table_renderer\n",
      "    value = unexpected_count_dict.get(\"value\")\n",
      "AttributeError: 'str' object has no attribute 'get'\n",
      "\".\n"
     ]
    }
   ],
   "source": [
    "context.run_checkpoint(checkpoint_name=ck0_name)\n",
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5 create a check point for another data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource_name: ge_demo\n",
      "expectation_suite_name: ge_demo.rules\n"
     ]
    }
   ],
   "source": [
    "ck1_name = \"pengfei_demo_checkpoint1\"\n",
    "print(f\"datasource_name: {datasource_name}\")\n",
    "dataset_name_1= \"adult_with_header.csv\"\n",
    "print(f\"expectation_suite_name: {expectation_suite_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: pengfei_demo_checkpoint1\n",
      "config_version: 1.0\n",
      "class_name: SimpleCheckpoint\n",
      "run_name_template: \"%Y%m%d-%H%M%S-my-run-name-template\"\n",
      "validations:\n",
      "  - batch_request:\n",
      "      datasource_name: ge_demo\n",
      "      data_connector_name: default_inferred_data_connector_name\n",
      "      data_asset_name: adult_with_header.csv\n",
      "      data_connector_query:\n",
      "        index: -1\n",
      "    expectation_suite_name: ge_demo.rules\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_config_1 = f\"\"\"\n",
    "name: {ck1_name}\n",
    "config_version: 1.0\n",
    "class_name: SimpleCheckpoint\n",
    "run_name_template: \"%Y%m%d-%H%M%S-my-run-name-template\"\n",
    "validations:\n",
    "  - batch_request:\n",
    "      datasource_name: {datasource_name}\n",
    "      data_connector_name: default_inferred_data_connector_name\n",
    "      data_asset_name: {dataset_name_1}\n",
    "      data_connector_query:\n",
    "        index: -1\n",
    "    expectation_suite_name: {expectation_suite_name}\n",
    "\"\"\"\n",
    "\n",
    "# preview the checkpoint config\n",
    "print(checkpoint_config_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"pengfei_demo_checkpoint1\",\n",
      "  \"config_version\": 1.0,\n",
      "  \"template_name\": null,\n",
      "  \"module_name\": \"great_expectations.checkpoint\",\n",
      "  \"class_name\": \"Checkpoint\",\n",
      "  \"run_name_template\": \"%Y%m%d-%H%M%S-my-run-name-template\",\n",
      "  \"expectation_suite_name\": null,\n",
      "  \"batch_request\": null,\n",
      "  \"action_list\": [\n",
      "    {\n",
      "      \"name\": \"store_validation_result\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreValidationResultAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"store_evaluation_params\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"update_data_docs\",\n",
      "      \"action\": {\n",
      "        \"class_name\": \"UpdateDataDocsAction\",\n",
      "        \"site_names\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"evaluation_parameters\": {},\n",
      "  \"runtime_configuration\": {},\n",
      "  \"validations\": [\n",
      "    {\n",
      "      \"batch_request\": {\n",
      "        \"datasource_name\": \"ge_demo\",\n",
      "        \"data_connector_name\": \"default_inferred_data_connector_name\",\n",
      "        \"data_asset_name\": \"adult_with_header.csv\",\n",
      "        \"data_connector_query\": {\n",
      "          \"index\": -1\n",
      "        }\n",
      "      },\n",
      "      \"expectation_suite_name\": \"ge_demo.rules\"\n",
      "    }\n",
      "  ],\n",
      "  \"profilers\": [],\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectation_suite_ge_cloud_id\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<great_expectations.checkpoint.checkpoint.SimpleCheckpoint at 0x7f1af3bbd640>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_checkpoint(**yaml.load(checkpoint_config_1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Calculating Metrics:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "781a34214ad5484dbcf53078dceecdce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An unexpected Exception occurred during data docs rendering.  Because of this error, certain parts of data docs will not be rendered properly and/or may not appear altogether.  Please use the trace, included in this message, to diagnose and repair the underlying issue.  Detailed information follows:\n",
      "            AttributeError: \"'str' object has no attribute 'get'\".  Traceback: \"Traceback (most recent call last):\n",
      "  File \"/home/pliu/.cache/pypoetry/virtualenvs/dataqualityandvalidation-6LYnP9NJ-py3.8/lib/python3.8/site-packages/great_expectations/render/renderer/content_block/validation_results_table_content_block.py\", line 163, in row_generator_fn\n",
      "    unexpected_table_renderer[1](result=result)\n",
      "  File \"/home/pliu/.cache/pypoetry/virtualenvs/dataqualityandvalidation-6LYnP9NJ-py3.8/lib/python3.8/site-packages/great_expectations/render/renderer/renderer.py\", line 13, in inner_func\n",
      "    return renderer_fn(*args, **kwargs)\n",
      "  File \"/home/pliu/.cache/pypoetry/virtualenvs/dataqualityandvalidation-6LYnP9NJ-py3.8/lib/python3.8/site-packages/great_expectations/expectations/expectation.py\", line 539, in _diagnostic_unexpected_table_renderer\n",
      "    value = unexpected_count_dict.get(\"value\")\n",
      "AttributeError: 'str' object has no attribute 'get'\n",
      "\".\n"
     ]
    }
   ],
   "source": [
    "context.run_checkpoint(checkpoint_name=ck1_name)\n",
    "context.open_data_docs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}